\chapter{Einleitung}
%TODO ausführlicher

Ein Sequenzalignment wird in der Bioinformatik dazu verwendet, zwei oder mehrere Sequenzen von zum Beispiel DNA-Strängen oder Proteinsequenzen miteinander zu vergleichen und die Verwandtschaft zu bestimmen. Ein Alignment ist das Ergebnis eines solchen Vergleichs. Bei einem globalen Alignment wird jeweils die gesamte Sequenz betrachtet, bei einem lokalen Alignment lediglich Teilabschnitte der beiden Sequenzen.
Um die verschiedenen Sequenzen vergleichen zu können, berechnet man einen Score oder die Kosten, um den Aufwand, den man betreiben muss, um die gegebenene Sequenz in die Zielsequenz umzuwandeln, beschreiben zu können. Hierbei wird jeweils das Optimum, also entweder der maximale Score oder die minimalen Kosten gesucht.
Die verschiedenen Schritte, um die Symbole der Strings zu verändern, sind bei Gleichheit ein 'match', bei der Substitution ein 'mismatch', bei der Löschung eine 'deletion' und bei der Einfügung eine 'insertion', welche je nach Verfahren unterschiedlich gewichtet werden können. Hierbei haben ähnliche Sequenzen einen hohen Score und geringe Kosten und unterschiedliche Sequenzen analog einen kleinen Score und hohe Kosten.

Ziel dieser Bachelorarbeit ist es, verschiedene Repräsentationen von paarweisen Sequenzalignments und deren Kodierungen zu beschreiben und zu vergleichen, sowie basierend auf einer eigenen Implementierung einer speichereffizienten Repräsentation Unterschiede zu diskutieren.

\section*{Die Edit-Operationen}

Die in diesem Kapitel eingeführten Begriffe werden in \cite[S. 5-7, 14-16]{gsa-skript} definiert.

Sei $\mathcal{A}$ eine endliche Menge von Buchstaben, die man Alphabet nennt. Für DNA-Sequenzen verwendet man üblicherweise die Menge der Basen, also $\mathcal{A} = \{a, c, g, t\}$. $\mathcal{A}^i$ sei die Menge der Sequenzen der Länge $i$ aus $\mathcal{A}$ und $\varepsilon$ sei die leere Sequenz. Formal ausgedrückt ist eine Edit-Operation ein Tupel 
\[(\alpha, \beta) \in (\mathcal{A}^1 \cup \{\varepsilon\}) \times (\mathcal{A}^1 \cup \{\varepsilon\}) \backslash \{(\varepsilon, \varepsilon)\}.\]

Eine äquivalente Schreibweise von $(\alpha,\beta)$ ist $\alpha \rightarrow \beta$. Es gibt drei verschiedene Edit-Operationen
\begin{align*}
a \rightarrow \varepsilon &\indent \text{ ist eine Deletion für alle }a \in \mathcal{A}\\
\varepsilon \rightarrow b &\indent \text{ ist eine Insertion für alle }b \in \mathcal{A}\\
a \rightarrow b &\indent \text{ ist eine Substitution für alle }a,b \in \mathcal{A}
\end{align*}
Dabei ist zu beachten, dass $\varepsilon \rightarrow \varepsilon$ keine Edit-Operation darstellt.

Ein Alignment von zwei Sequenzen $u$ und $v$ lässt sich nun als eine Sequenz $(\alpha_1 \rightarrow \beta_1, ... , \alpha_h \rightarrow \beta_h)$ von Edit-Operationen definieren, sodass $u = \alpha_1 ... \alpha_h$ und $v = \beta_1 ... \beta_h$ gilt.

Üblicherweise wird ein Alignment in drei Zeilen wie folgt geschrieben. In der ersten Zeile schreibt man die Sequenz $u$ und in der dritten Zeile die Sequenz $v$. In der mittleren Zeile symbolisiert das Zeichen '$|$' einen Match. Außerdem wird ein $\varepsilon$ aus der Edit-Operation durch das Zeichen '$-$' dargestellt.

\begin{bsp}
	Sei von $u$ und $v$ das folgende Alignment $A = (a\rightarrow a, c\rightarrow c, t\rightarrow t, \varepsilon \rightarrow a, g \rightarrow g, a \rightarrow a, a \rightarrow a, c \rightarrow \varepsilon, t \rightarrow t)$ gegeben. 
	\begin{center}
		\texttt{
			\begin{tabular}{ccccccccc}
				a & c & t & - & g & a & a & c & t\\
				$|$&$|$&$|$&&$|$&$|$&$|$& &$|$\\
				a&c&t&a&g&a&a& - &t
			\end{tabular}
		}
	\end{center}
	\label{Bsp1}
\end{bsp}
%TODO noch was?

\section*{Die Edit-Distanz}

Sei eine Kostenfunktion $\delta$ mit $\delta(a\rightarrow b)\geq 0$ für alle Substitutionen $a \rightarrow b$ und $\delta(\alpha \rightarrow \beta)>0$ für alle Einfügungen und Löschungen $\alpha \rightarrow \beta$ gegeben. Die Kosten für ein Alignment $A = (\alpha_1 \rightarrow \beta_1, ... , \alpha_h \rightarrow \beta_h)$ ist die Summe der Kosten aller Edit-Operationen des Alignments.
\[\delta(A) = \sum_{i=1}^{h}\delta(\alpha_i \rightarrow \beta_i)\]
Ein Beispiel einer Kostenfunktion ist die Einheitskostenfunktion
\[
\delta(\alpha \rightarrow \beta) = 
\begin{cases} 
0 ,& \text{wenn } \alpha,\beta \in \mathcal{A} \text{ und } \alpha=\beta \\
1 , & \text{sonst.}
\end{cases}
\]
Die Edit-Distanz von zwei Sequenzen ist wie folgt definiert:
\[edist_\delta(u,v) = \min\{\delta(A) \mid A \text{ ist Alignment von }u \text{ und }v\}\]
Ein Alignment A ist optimal, wenn $\delta(A) = edist_\delta(u,v)$ gilt.\\[0,5cm]
Wenn $\delta$ die Einheitskostenfunktion ist, so ist $edist_\delta(u,v)$ die Levenshtein Distanz \cite[S. 19-21]{gsa-skript}.

%Ein Alignment kann für eine Edit-Distanz $e$ mit der Einheitskostenfunktion in $O(e)$ Zeit berechnet werden \cite[S. 41-42]{gsa-skript}.

\chapter{Methoden}

\section{CIGAR-Strings}

Ein Dateiformat, welches zur Speicherung von Alignments verwendet wird, ist das SAM-Format oder die binär komprimierte Version BAM. Dieses codiert ein Alignment in einem sogenannten CIGAR-String, der aus einzelnen Zeichen besteht, die jeweils eine Edit-Operation bezeichnen, also M für eine Substitution, I für eine Insertion und D für eine Deletion. Gleiche aufeinanderfolgende Operationen werden als Kombination von Quantität und Symbol geschrieben.

\begin{defi}
Eine Folge von abwechselnd Quantitäten und Edit-Operationen $C = s_1c_1s_2c_2...s_nc_n$ ist ein CIGAR-String mit der Länge $|C| = 2n$ eines Alignments für alle Symbole $s \in \{$M$,$I$,$D$\}$ und alle Quantitäten $c \in \mathbb{N}$.
\end{defi}

\begin{bsp}
Sei folgendes Alignment aus Beispiel \ref{Bsp1} gegeben.
\begin{center}
	\texttt{
		\begin{tabular}{ccccccccc}
			a & c & t & - & g & a & a & c & t\\
			$|$&$|$&$|$&&$|$&$|$&$|$& &$|$\\
			a&c&t&a&g&a&a& - &t
		\end{tabular}
	}
\end{center}
Dieses Alignment wird duch den CIGAR-String \texttt{3M1I3M1D1M} repräsentiert \cite{sam}.
\end{bsp}

\subsection{Kodierung eines CIGAR-Strings}\label{Cigar_Speicher}

Für die Kodierung eines CIGAR-Strings ist es sinnvoll, alle Quantitäten und Symbole seperat zu kodieren, um so mit kleineren Alphabeten für die zu kodierenden Symbole arbeiten zu können.

$\cal{A}$$_s = \{M, I, D\}$ und $\cal{A}$$_c = \{s_i \mid 1 \leq i \leq n\}$ sind somit die Alphabete der zu kodierenden Symbole eines CIGAR-Strings.

Drei der gängigsten Kodierungsverfahren sind die naive binäre Kodierung, die unäre Kodierung und die Huffman-Kodierung.

%binär
Bei einer naiven binären Kodierung wird jedes Symbol $a \in \cal{A}$ mit $\lceil \log_2$$|\cal{A}|$
$\rceil$ Bit kodiert, was den Vorteil hat, dass alle Codewörter die gleiche Länge haben.

%unär
Die unäre Kodierung kodiert jedes Symbol nach der Häufigkeit des Auftretens im Alphabet mit $i - 1$ $'0'$-Bits, gefolgt von einem $'1'$-Bit, wobei $i$ die Position des Symbols in einer nach der Häufigkeit absteigend sortierten Liste ist. Das am Häufigsten auftretende Symbol des Alphabets wird also mit $'1'$, das zweithäufigste mit $'01'$, das dritthäufigste mit $'001'$ usw. kodiert \cite[S. 29-30]{coding}. Diese Art der Kodierung bietet sich insbesondere dann an, wenn ein zu kodierendes Symbol deutlich häufiger auftritt, als die anderen Symbole. Außerdem hat jedes Codewort die Größe $1$, was den Vorteil hat, dass lediglich die Länge variiert.

%TODO Skript Mail Prof
%canonical Huffman
Bei einer \textit{minimalen} binären Kodierung, wie sie auch im Huffman-Alogrithmus verwendet wird, werden die Längen der Codewörter anhand der Häufigkeiten der Symbole in der zu kodierenden Sequenz angepasst. Somit lässt sich eine Kodierung ermöglichen, welche im Durchschnitt weniger Bit pro Symbol beansprucht. Jedes Codewort ist dabei nie der Anfang eines anderen Codewortes, was den Code präfixfrei macht und die Codewörter somit eindeutig zugeordnet werden können \cite[S. 53-57]{coding}. 

Als Datenstruktur wird hierbei eine priorisierte Queue verwendet, welche nach den Häufigkeiten der Symbole sortiert ist. Der Algorithmus wählt immer die zwei Symbole mit den geringsten Häufigkeiten aus und fügt sie als ein Symbol zusammen, bis am Ende alle Symbole zusammengefügt wurden. So wird rekursiv ein Baum aufgebaut, welcher am Ende durch das Hinzufügen von den Kantengewichten $0$ und $1$ die Kodierungen der einzelnen Symbole bestimmt.

Immer wenn die Wahl zwischen mehreren Symbolen mit der selben Häufigkeit getroffen werden muss, kann eine Regel eingeführt werden. Zum Beispiel können immer die zwei Symbole, die im Alphabet oder numerisch vor den anderen stehen, ausgewählt werden. Hierdurch vermeidet man die generierung unterschiedlicher Kodierungen.

Dieser 'kanonische' Huffman-Algorithmus benötigt aufgrund der oben genannten  Eigenschaften lediglich die Anzahl der Codewörter für jede vorhandene Codewortlänge, sowie die sortierten Symbole benötigt, um die Informationen zu dekodieren \cite{canonical}. 

Im Folgenden vergleiche ich ausführlich für den CIGAR-String eines Alignments die Verfahren der naiven binären Kodierung, der unären Kodierung und der Huffman-Kodierung.

\FloatBarrier

\begin{bsp}
Sei das Alignment $A$

\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0   
\end{verbatim}
gegeben, welches durch den CIGAR-String \texttt{4M1I1M1I1M1I1M2D1M1D1M1I8M\\1D7M1D5M1I4M} repräsentiert werden kann.

Sei außerdem das Alphabet $\cal{A}$$_s$ $= \{$M, I, D$\}$, welches alle Symbole aus dem CIGAR-String enthält, das Alphabet $\cal{A}$$_c$ $= \{1, 2, 4, 5, 7, 8\}$, welches alle Zahlen aus dem CIGAR-String enthält, sowie die Häufigkeiten jeden Symbols gegeben.

Bei einer naiven binären Kodierung wird jedes Symbol $a \in \cal{A}$$_{s,c}$ mit $\lceil \log_23\rceil + \lceil \log_26\rceil = 2 + 3 = 5$ Bit pro Symbol kodiert. Insgesamt ergibt das somit $19 \cdot 5 = 95$ Bit.

Die unäre Kodierung des oben genannte CIGAR-Strings ist in Tabelle \ref{cigar-unary} beschrieben. Sie benötigt folglich $32 + 35 = 67$ Bit.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
		\hline
		M & $10$ & $1$ & $10 \cdot 1 = 10$\\
		D & $5$ & $01$ & $5 \cdot 2 = 10$\\
		I & $4$ & $001$ & $4 \cdot 3 = 12$\\
		&&&\\
		&&&\\
		&&&\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$32$
	\end{tabular}
	
	\begin{tabular}{cccr}
	Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
	\hline
	$1$ & $13$ &$1$ & $13 \cdot 1 = 13$\\
	$4$ & $2$ &$01$ & $2 \cdot 2 = \ \ 4$\\
	$2$ & $1$ &$001$ & $1 \cdot 3 =\ \ 3$\\
	$5$ & $1$ &$0001$ & $1 \cdot 4 =\ \ 4$\\
	$7$ & $1$ &$00001$ & $1 \cdot 5 =\ \ 5$\\
	$8$ & $1$ &$000001$ & $1 \cdot 6 =\ \ 6$\\
	\hline
	\multicolumn{3}{l}{Gesamtanzahl:}&$35$
\end{tabular}
\caption{Unäre Kodierung des CIGAR-Strings}
\label{cigar-unary}
\end{table}

Der kanonische Huffman-Algorithmus würde bei dem oben genannten Beispiel des CIGAR-Strings nach \cite[S. 54]{coding} die Symbole wie in Tabelle \ref{cig-huf-coding} beschrieben kodieren. Die Huffman-Bäume beider Alphabete sind in Abbildung \ref{Huff-Tree-Cig} dargestellt. Für die Dekodierung sind somit zusätzlich die Listen $(1,2),($M$, $D$, $I$)$ und $(1,1,0,4),(1,4,2,5,7,8)$ zu speichern. Diese können als sogenannter 'Header' am Anfang der kodierten Datei unär kodiert werden. In diesem Fall würde der Header als $01001;0001$ und $0101100001;0000001$ kodiert werden, wobei jeweils der erste Teil die Häufigkeiten der Code-Längen und der zweite Teil die Gesamtanzahl der Symbole kodiert.

Die Größe dieser Kodierung ist demnach $28 + 33 + 9 + 17 = 87$ Bit.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung & Anzahl Bits\\
		\hline
		M & $10$ &$0$ & $10 \cdot 1 = 10$\\
		D & $5$ &$10$ & $5 \cdot 2 = 10$\\
		I & $4$ &$11$ & $4 \cdot 2 =\ \ 8$\\
		&&&\\
		&&&\\
		&&&\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$28$
	\end{tabular}
	
	\begin{tabular}{cccr}
	Symbol & Häufigkeit & Kodierung & Anzahl Bits\\
	\hline
	$1$ & $13$ & $0$ & $13 \cdot 1 = 13$\\
	$4$ & $2$ & $10$ & $2 \cdot 2 =\ \ 4$\\
	$2$ & $1$ & $1100$ & $1 \cdot 4 =\ \ 4$\\
	$5$ & $1$ & $1101$ & $1 \cdot 4 =\ \ 4$\\
	$7$ & $1$ & $1110$ & $1 \cdot 4 =\ \ 4$\\
	$8$ & $1$ & $1111$ & $1 \cdot 4 =\ \ 4$\\
	\hline
	\multicolumn{3}{l}{Gesamtanzahl:}&$33$
\end{tabular}
\caption{Huffmann-Kodierung des CIGAR-Strings}
\label{cig-huf-coding}
\end{table}

\begin{figure}[t]
	\centering
	\begin{forest}
		for tree={grow'=south}
		[$\frac{19}{38}$
		[$\frac{9}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[I, edge label={node[midway,right,font=\scriptsize]{1}}]
		[D, edge label={node[midway,left,font=\scriptsize]{0}}] ] 
		[M, edge label={node[midway,left,font=\scriptsize]{0}}] ]
		]
	\end{forest}
	\begin{tabular}{ccc}
		&&
	\end{tabular}
	\begin{forest}
		for tree={grow'=south}
		[$\frac{19}{38}$
		[$\frac{6}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$\frac{4}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$\frac{2}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$8$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$7$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$\frac{2}{38}$, edge label={node[midway,left,font=\scriptsize]{0}}
		[$5$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$2$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]]
		[$4$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$1$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]
	\end{forest}
	\caption{Huffman-Bäume der Kodierung des CIGAR-Strings}
	\label{Huff-Tree-Cig}
\end{figure}
\end{bsp}

\section{Trace Point Konzept}

Ein neuer Ansatz der speichereffizienten Repräsentation von Alignments wurde von Gene Myers in \cite{myers} beschrieben und basiert auf dem Konzept der Trace Points.

%TODO Idee beschreiben

Sei $A$ ein Alignment von $u[i...j]$ und $v[k...\ell]$ mit $i < j$ und $k < l$ und sei $\Delta \in \mathbb{N}$. Sei $p = \left \lceil\frac{i}{\Delta}\right \rceil$. Man unterteilt $u[i...j]$ in $\tau = \left \lceil\frac{j}{\Delta}\right \rceil - \left \lfloor\frac{i}{\Delta}\right \rfloor$ Substrings $u_0, u_1, ... , u_{\tau -1}$ mit
\[  
u_q =
\begin{cases} 
u[i...p\cdot\Delta] & \text{falls }q = 0 \\
u[(p+q-1)\cdot\Delta+1...(p+q)\cdot\Delta] & \text{falls }0<q<\tau -1\\
u[(p+\tau-2)\cdot\Delta...j] & \text{falls }q = \tau -1
\end{cases}
\]

Für alle $q$ mit $ 0 \leq q < \tau -1$ sei $t_q$ der letzte Index des Substrings von $v$, der in A mit $u_q$ aligniert. $t_q$ nennt man Trace Point. Für $q = 0$ aligniert $u_0$ mit $v_0 = v[k...t_0]$. Für alle $q$ mit $0<q< \tau -1$ aligniert $u_q$ mit $v_q = v[t_{q-1}+1...t_q]$.

Seien $i,j,k,\ell,\Delta$ und die Trace-Points eines Alignments von $u$ und $v$ gegeben. Dann kann ein Alignment $A'$ von $u$ und $v$ mit $\delta (A') \leq \delta (A)$ konstruiert werden. Danach bestimmt man aus den Trace-Points die Substring-Paare $u_q$ und $v_q$, berechnet hierfür jeweils ein optimales Alignment und konkateniert die Alignments von den aufeinanderfolgenden Substring-Paaren zu $A'$.

\begin{bsp}

Sei $\Delta = 15$ und folgendes Alignment gegeben:

\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0    
\end{verbatim}

Beide Sequenzen seien in dem Intervall $0...37$. Das Alignment wird wie oben beschrieben in $\tau = \left \lceil\frac{37}{15}\right \rceil - \left \lfloor\frac{0}{15}\right \rfloor = 3 - 0 = 3$ Abschnitte unterteilt. Der erste Abschnitt ist in $u$ von $0$ bis $14$ und in $v$ von $0$ bis $15$.

\begin{verbatim}
gagc-a-t-gttgcc-tgg
|| | | | |  | | |||
gaccaagtag--g-cgtgg
\end{verbatim}

Der zweite Abschnitt ist in $u$ von $15$ bis $29$ und in $v$ von $16$ bis $28$.

\begin{verbatim}
tcctttgctaggtac
|||| ||| ||| |
acctt-gctcggt-c
\end{verbatim}

Der dritte Abschnitt ist in $u$ von $30$ bis $37$ und in $v$ von $29$ bis $37$.

\begin{verbatim}
tgta-gaga
|||| ||||
tgtaagaga
\end{verbatim}

Somit ergeben sich als Endpunkte aller Abschnitte außer dem letzten die Trace Points $15$ und $28$.
\end{bsp}

%\subsection{Komplexität}

%TODO ausführlicher
%Für die Trace-Point Repräsentation wird für eine Edit-Distanz $e$ mit Einheitskosten als Kostenfunktion $\delta$ wie oben beschrieben lediglich $O(e^2)$ Zeit pro Teilalignment benötigt, wobei bei einer erwarteten Fehlerrate $\varepsilon$ des Alignments die Edit-Distanz immer höchstens so groß ist wie die Anzahl der Fehler im Teilalignment \cite[S.41-42]{gsa-skript}.

\subsection{Differenzen-Kodierung}\label{Differenzen-Kodierung}

%TODO Quellen
Gegeben sei eine Liste $L = (a_1, a_2, ... , a_n)$ mit $a_i < a_{i+1}, 0 < i < n$.

Anstatt jeden Wert $a \in L$ als solchen abzuspeichern, kann alternativ die Differenz eines Wertes $a_i$ zu dem nachfolgenden Wert $a_{i+1}$ abgespeichert werden. Lediglich der erste (oder letzte) Wert aus $L$ wird benötigt, um später sukzessive die ursprüngliche Liste rekonstruieren zu können.
\[L_{\mathit{diff}} = (a_1, (a_2-a_1), (a_3-a_2), ... , (a_{n}-a_{n-1}))\]

Bei gleichmäßig ansteigenden Werten ist die Abweichung der Differenzen zweier aufeinanderfolgender Werte in der Liste untereinander gering und die Menge der zu kodierenden Symbole verringert sich.

Im Folgenden Beispiel werde ich die Kodierung der Trace Point Differenzen ausführlich für die naive binäre, unäre und Huffman-Kodierung erläutern.

\begin{bsp}
Sei $\Delta = 5$ und das Alignment $A$
\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0   
\end{verbatim}

wie in Abschnitt \ref{Cigar_Speicher} mit den dazugehörigen TracePoints $5, 10, 15, 20, 24, 28$ und $34$ gegeben. Es ergibt sich somit das Alphabet $\cal{A}$ $= \{5, 10, 15, 20, 24, 28, 34\}$ mit ausschließlich positiven und aufsteigenden Werten.

Für die Trace Point Darstellung ist in diesem Beispiel somit eine Differenzen-Kodierung möglich.

Als neue Liste zu kodierender Werte ergibt sich nach \ref{Differenzen-Kodierung} $L_{\mathit{diff}} = (5, 5, 5, 5, 4, 4, 6)$.

Um aus den Trace Points ein neues Alignment rekonstruieren zu können, benötigt man zusätzlich mindestens den $\Delta$-Wert, damit die Grenzen der Substrings beider Sequenzen berechnet werden können. Hierfür muss also der $\Delta$-Wert zu $L_{\mathit{diff}}$ hinzugefügt werden.

Für das oben genannten Beispiel ergibt sich somit
\begin{center}
\begin{tabular}{rcl}
	$L_{\mathit{diff}}$ &$=$& $(\Delta, a_1, (a_2-a_1), (a_3-a_2), ... , (a_{n}-a_{n-1}))$\\
	&$=$ & $(5, 5, 5, 5, 5, 4, 4, 6)$
\end{tabular}
\end{center}

sowie das Alphabet $\cal{A}$ $= \{4, 5, 6\}$. 

Bei der naiven binären Kodierung von $L_{\mathit{diff}}$ ergibt sich analog zu \ref{Cigar_Speicher} ein Bedarf von $\lceil \log_28\rceil = 3$ Bit pro Symbol, also $8 \cdot 3 = 24$ Bit insgesamt und damit nur  $\frac{24}{95} = 25.26$\% der binären Kodierung für den CIGAR-String.

Die unäre Kodierung ergibt für dieses Beispiel die in Tabelle \ref{diff-unary} beschriebene Kodierung. Die Größe dieser Kodierung ist demnach $12$ Bit und benötigt damit nur $\frac{12}{67} = 17.91$\% der unären Kodierung für den CIGAR-String.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
		\hline
		$5$ & $5$ &$0$ & $5 \cdot 1 = 5$\\
		$4$ & $2$ &$10$ & $2 \cdot 2 = 4$\\
		$6$ & $1$ &$110$ & $1 \cdot 3 = 3$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$12$
	\end{tabular}
	\caption{Unäre Kodierung der Differenzen-Kodierung}
	\label{diff-unary}
\end{table}

Die Ausführung des Huffman-Algorithmus kodiert nach \cite[S. 54]{coding} die Symbole wie in Tabelle \ref{Diff-Huff} aufgelistet. Der dazugehörige Huffmann-Baum aus \ref{Huff-Tree-Diff} verdeutlicht die Kodierung der einzelnen Symbole, muss aber für den kanonischen Huffman-Algorithmus, wie in \ref{Cigar_Speicher} beschrieben, nicht komplett gespeichert werden. Aufgrund der Beschaffenheit der Codewörter des kanonischen Huffman-Algorithmus ist hier lediglich die Speicherung der Listen $(1,2),(5,4,6)$, welche als $10110;1110$ im Header kodiert werden, nötig.

Die Größe der kanonischen Huffman-Kodierung ist demnach $11 + 10 = 21$ Bit und benötigt damit nur $\frac{21}{70} = 30$\% der Huffman-Kodierung für den CIGAR-String.

\begin{table}
	\centering
	\begin{tabular}{ccr}
		Symbol & Kodierung & Anzahl Bits\\
		\hline
		$5$ & $0$ & $5 \cdot 1 = 5$\\
		$4$ & $10$ & $2 \cdot 2 = 4$\\
		$6$ & $11$ & $1 \cdot 2 = 2$\\
		\hline
		\multicolumn{2}{l}{Gesamtanzahl:}&$11$
	\end{tabular}
	\caption{Huffman-Kodierung der Differenzen-Kodierung}
	\label{Diff-Huff}
\end{table}

\begin{figure}
	\centering
	\begin{forest}
		for tree={grow'=south}
		[$\frac{8}{8}$
		[$\frac{3}{8}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$6$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$4$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$5$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]
	\end{forest}
	\caption{Huffman-Baum der Differenzen-Kodierung}
	\label{Huff-Tree-Diff}
\end{figure}
\end{bsp}

\section{Entropie der Methoden}

Die Entropie $H$ beschreibt den durchschnittlichen Informationsgehalt einer Sequenz $S$ für alle Symbole $a \in S$ mit den relativen Wahrscheinlichkeiten $p(a)$ jeden Symbols in der Einheit $\frac{\text{Bit}}{\text{Symbol}}$.
\[H(S) = - \sum_{a \in S}p(a) \cdot \log_2p(a)\]
Sie ist maximal, wenn alle Symbole mit der gleichen Wahrscheinlichkeit $\frac{1}{|S|}$ auftreten \cite{entropy}.

Für den in \ref{Cigar_Speicher} genannten CIGAR-String ergibt sich eine Entropie von

\begin{center}
\begin{tabular}{rcl}
	$H(\mathit{Cigar})$ &$=$& $-(\frac{10}{38} \cdot \log_2\frac{10}{38} + \frac{5}{38} \cdot \log_2\frac{5}{38} + \frac{4}{38} \cdot \log_2\frac{4}{38} + \frac{13}{38} \cdot \log_2\frac{13}{38} + \frac{2}{38} \cdot$\\
	&&$\log_2\frac{2}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38})$\\
	&$\approx$& $2.54\ \frac{\text{Bit}}{\text{Symbol}}$
\end{tabular}
\end{center}

Die in \ref{Differenzen-Kodierung} genannten Trace Point Differenzen des selben Alignments ergeben analog

\begin{center}
\begin{tabular}{rcl}
	$H(\mathit{Diff})$ &$=$& $-(\frac{5}{8} \cdot \log_2\frac{5}{8} + \frac{2}{8} \cdot \log_2\frac{2}{8} + \frac{1}{8} \cdot \log_2\frac{1}{8})$\\
	&$\approx$& $1.30\ \frac{\text{Bit}}{\text{Symbol}}$
\end{tabular}
\end{center}

%TODO Tabelle mit Bits

\chapter{Resultate}

\section{CIGAR Kodierung}\label{Cigar_Testläufe}

%TODO das in die Caption
Die ersten drei der folgenden Grafiken wurden mit jeweils \numprint{10000} zufällig generierte Sequenzpaaren mit je etwa \numprint{1000} Basen, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $100$ berechnet und auf $10$ Bit gerundet.
Die letzten drei der Grafiken wurden mit jeweils $100$ zufällig generierten Sequenzpaaren mit je etwa $10.000$ Basen, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $100$ berechnet und auf 10 Bit gerundet.

%Cigar Binary Mean: 294.265
%Cigar Unary Mean: 275.7039
%Cigar Huffman Mean: 166.7186

%Cig Bin/Una: 1.06732258775
%Cig Una/Bin: 0.936923861146
%Cig Bin/Huf: 1.76504001353
%Cig Huf/Bin: 0.566559393744
%Cig Huf/Una: 0.604701638243
%Cig Una/Huf: 1.65370810455

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-bin-10000-1000-d100}
	\caption{Größe der naiven binären Kodierung für einen CIGAR-String eines paarweisen Sequenz-Alignments in Bit}\label{fig:cig-bin}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-una-10000-1000-d100}
	\caption{Größe der unären Kodierung für einen CIGAR-String eines paarweisen Sequenz-Alignments in Bit}\label{fig:cig-una}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-huf-10000-1000-d100-canon}
	\caption{Größe der Huffman-Kodierung für einen CIGAR-String eines paarweisen Sequenz-Alignments in Bit}\label{fig:cig-huf}
\end{figure}

%Huffman Mean: 387.3798

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-bin-100-10000-d100-canon}
	\caption{Größe der binären Kodierung für einen CIGAR-String eines paarweisen Sequenz-Alignments in Bit}\label{big-cig-bin}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-una-100-10000-d100-canon}
	\caption{Größe der unären Kodierung für einen CIGAR-String eines paarweisen Sequenz-Alignments in Bit}\label{big-cig-una}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-huf-100-10000-d100-canon}
	\caption{Größe der Huffman-Kodierung für einen CIGAR-String eines paarweisen Sequenz-Alignments in Bit}\label{big-cig-huf}
\end{figure}

%TODO Text letzten drei Grafiken
%TODO diese Grafiken neu machen mit 50er Buckets, oder 100er, brauchen aber 7390 Sekunden
\FloatBarrier

%TODO neu mit 10er Bucket
%100 10000 d100 ergab:
%Binary Mean: 3942.06
%Unary Mean: 4797.495
%Huffman Mean: 1734.18

%Bin/Una: 0.821691320158
%Una/Bin: 1.21700202432
%Bin/Huf: 2.27315503581
%Huf/Bin: 0.439917200651
%Huf/Una: 0.361476145363
%Una/Huf: 2.76643428018

Die naive binäre Kodierung der CIGAR-Strings benötigt wie in Abbildung \ref{fig:cig-bin} dargestellt für $10000$ Sequenzpaare mit je $1000$ Basen im Mittel $294.27$ Bit, wobei Werte zwischen $50$ und $900$ Bit erreicht werden. Diese bilden zwei Maxima bei $1800$ Sequenzpaaren mit jeweils etwa $120$ Bit als globales Maximum und $700$ Sequenzpaaren mit jeweils etwa $450$ Bit als lokales Maximum. Für $100$ Sequenzpaare mit je $10000$ Basen werden, wie in Abbildung \ref{big-cig-bin} zu sehen ist, Werte zwischen $900$ und $7500$ Bit mit einem Mittelwert von $3942.06$ Bit erreicht, wobei hier eine ähnliche Verteilung wie in Abbildung \ref{fig:cig-bin} auftritt. Die Maxima liegen hier bei $8$ Sequenzpaaren mit $1100$ Bit und $5$ Sequenzpaare mit $6700$ Bit.

Wie in Abbildung \ref{fig:cig-una} zu erkennen ist, ähnelt die Anzahl der Bits für die unäre Kodierung der CIGAR-Strings für $10000$ Sequenzpaare mit je $1000$ Basen der der naiven binären Kodierung. Hier werden ebenfalls zwei Maxima erreicht, wobei hier das globale Maximum bei $1900$ Sequenzpaaren mit etwa $150$ Bit und das lokale Maximum bei $500$ Sequenzpaaren mit etwa $450$ Bit liegt. Für die unäre Kodierung wird im Mittel $275.70$ Bit für die Kodierung eines CIGAR-Strings und damit nur etwa $6.3$\% weniger als bei der naiven binären Kodierung benötigt. Für $100$ Sequenzpaare mit je $10000$ Basen werden, wie in Abbildung \ref{big-cig-una} dargestellt, ebenfalls zwei Maxima erreicht, einmal bei $9$ Sequenzpaaren zu $1700$ Bit und $4$ Sequenzpaare mit $8500$ Bit. Der Mittelwert liegt hier bei $4794.50$ Bit.

Die Huffman-Kodierung kodiert wie in Abbildung \ref{fig:cig-huf} zu erkennen ist die CIGAR-Strings für $10000$ Sequenzpaare mit je $1000$ Basen zwischen $200$ und $550$ Bit. Die Bitanzahl ist hier nahezu normalverteilt mit einem Maximum von $1500$ Sequenzpaaren für etwa $390$ Bit, was in etwa dem Durchschnitt von $387.38$ Bit entspricht. Für $100$ Sequenzpaare mit je $10000$ Basen werden, wie in Abbildung \ref{big-cig-huf} zu sehen ist, zwischen $1500$ und $1900$ Bit benötigt, wobei das Maximum bei $11$ Sequenzpaaren mit $1750$ Bit liegt und damit dem Mittelwert von $1734.18$ Bit entspricht.



\section{Differenzen Kodierung}\label{Diff-Testläufe}

Die ersten beiden der folgenden Grafiken wurden mit jeweils $10.000$ zufällig generierte Sequenzpaaren mit je etwa $1.000$ Basen, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $100$ berechnet und auf $3$ Bit gerundet.
Die letzten beiden Grafiken wurden mit jeweils $100$ zufällig generierte Sequenzpaaren mit je etwa $10.000$ Basen, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $100$ berechnet und auf $3$ Bit gerundet.

%neu mit canonical
%Binary Mean: 40.0
%Unary Mean: 24.5165
%Huffman Mean: 37.9864

%Bin/Una: 1.63155425938
%Una/Bin: 0.6129125
%Bin/Huf: 1.05300844513
%Huf/Bin: 0.94966
%Huf/Una: 1.54942181796
%Una/Huf: 0.645402038624

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=13cm]{coding/bucket-diff-bin-10000-1000-d100}
%	\caption{Bitverbrauch der naiven binären Kodierung der Delta-Kodierung}\label{fig:diff-bin}
%\end{figure}

\FloatBarrier

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket3-diff-una-10000-1000-d100-canon}
	\caption{Größe der unären Kodierung für die Differenzen der Trace Points eines paarweisen Sequenz-Alignments in Bit}\label{fig:diff-una}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket3-diff-huf-10000-1000-d100-canon}
	\caption{Größe der Huffman-Kodierung für die Differenzen der Trace Points eines paarweisen Sequenz-Alignments in Bit}\label{fig:diff-huf}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket3-diff-una-100-10000-d100}
	\caption{Größe der unären Kodierung für die Differenzen der Trace Points eines paarweisen Sequenz-Alignments in Bit}\label{big-diff-una}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket3-diff-huf-100-10000-d100}
	\caption{Größe der Huffman-Kodierung für die Differenzen der Trace Points eines paarweisen Sequenz-Alignments in Bit}\label{big-diff-huf}
\end{figure}

%Binary Mean: 700.0
%Unary Mean: 323.2
%Huffman Mean: 115.04

%Bin/Una: 2.16584158416
%Una/Bin: 0.461714285714
%Bin/Huf: 6.08484005563
%Huf/Bin: 0.164342857143
%Huf/Una: 0.355940594059
%Una/Huf: 2.80945757997

\FloatBarrier

Die naive binäre Kodierung benötigt für $10000$ Sequenzpaare mit $1000$ Basen und einem $\Delta$-Wert von $100$ in jedem Durchlauf und somit auch im Mittel konstant $40$ Bit, da für jeden Durchlauf $9$ Trace Points und der $\Delta$-Wert gespeichert werden für $\lceil \log_210 \rceil \cdot 10 = 40$ Bit. Für $100$ Sequenzpaare mit $10000$ und einem $\Delta$-Wert von $100$ werden in jedem Durchlauf und im Mittel $700$ Bit benötigt, da $\lceil \log_2100 \rceil \cdot 100 = 700$ Bit für die binäre Kodierung benötigt werden.

Für die unäre Kodierung der Differenzen der Trace Points wird für $10000$ Sequenzpaare mit $1000$ Basen, wie in Abbildung \ref{fig:diff-una} verdeutlicht, zwischen $12$ und $45$ Bit benötigt. Die Bitanzahl ist in etwa normalverteilt, wobei das Maximum bei $3050$ Sequenzpaaren mit $26$ Bit liegt. Im Mittel  wird für diese Kodierung $24.49$ Bit und damit nur etwa $61.22$\% der binären Kodierung benötigt. Für $100$ Sequenzpaare mit je $10000$ Basen werden, wie in Abbildung \ref{big-diff-una} dargestellt, zwischen $290$ und $390$ Bit mit einem Maximum bei $8$ Sequenzpaaren und $320$ Bit benötigt, wobei der Mittelwert bei $323.2$ Bit liegt.

Die Huffman-Kodierung kodiert für $10000$ Sequenzpaare mit $1000$ Basen, wie in Abbildung \ref{fig:diff-huf} zu sehen ist, die Differenzen der Trace Points mit $3$ bis $30$ Bit, wobei hier das Maximum bei $2600$ Sequenzpaaren mit $15$ Bit liegt. Sie benötigt durchschnittlich nur $13.90$ Bit und damit nur etwa $56.75$\% des Speicherbedarfs der unären und $34.74$\% der naiven binären Kodierung. Für $100$ Sequenzpaare mit $10000$ Basen wird, wie in Abbildung \ref{big-diff-huf} dargestellt, zwischen $70$ und $170$ Bit benötigt, wobei das Maximum bei $20$ Sequenzpaaren mit $110$ Bit und der Mittelwert bei $114.04$ Bit liegt.

%Cigar Binary Mean: 294.265
%Cigar Unary Mean: 275.7039
%Cigar Huffman Mean: 166.7186
%Diff Binary Mean: 40.0
%Diff Unary Mean: 24.4888
%Diff Huffman Mean: 13.8965

%Cig Bin/Una: 1.06732258775
%Cig Una/Bin: 0.936923861146
%Cig Bin/Huf: 1.76504001353
%Cig Huf/Bin: 0.566559393744
%Cig Huf/Una: 0.604701638243
%Cig Una/Huf: 1.65370810455

%Diff Bin/Una: 1.63339975826
%Diff Una/Bin: 0.61222
%Diff Bin/Huf: 2.8784226244
%Diff Huf/Bin: 0.3474125
%Diff Huf/Una: 0.567463493515
%Diff Una/Huf: 1.76222789911
%Unterschied Bin: 0.135931898119
%Unterschied Una: 0.0888228276785
%Unterschied Huf: 0.0833530271967

\section{Entropie der Repräsentationen}

Die folgenden Grafiken zeigen die Entropie der CIGAR-Strings und Trace Point Differenzen von $10.000$ zufällig generierten Sequenzpaaren mit je etwa $1.000$ Basen, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $100$.

%Cig Entropy Mean: 323.981150901
%Diff Entropy Mean: 21.5313812847
%cig/diff: 15.0469283237
%diff/cig: 0.0664587468278

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket10-cig-ent-10000-1000-d100}
	\caption{Entropie des CIGAR-Strings}
	\label{cig-ent}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/Buckets/bucket3-diff-ent-10000-1000-d100}
	\caption{Entropie der Trace Point Differenzen}
	\label{diff-ent}
\end{figure}

Die Entropie für die CIGAR-String Repräsentation liegt für die gegebenen Sequenzpaare, wie in Abbildung \ref{cig-ent} zu erkennen ist, zwischen $110$ und $580$ Bit, wobei der Durchschnittswert bei $323.98$ Bit liegt. Die Werte sind normalverteilt, wobei das Maximum bei $700$ Sequenzpaaren, welche mit etwa $320$ Bit kodiert wurden, liegt.

Die Differenzen der Trace Points weisen hingegen, wie in Abbildung \ref{diff-ent} verdeutlicht, eine Entropie im Bereich von $6$ bis $30$ Bit auf, wobei der Durchschnittswert von $21.53$ Bit nur etwa $7$\% des Durchschnittwertes der CIGAR-String Repräsentation ausmacht. Das Maximum der nahezu normalverteilten Entopie-Werte liegt hier bei etwa $21$ Bit, mit welchem  $4000$ Sequenzpaare kodiert wurden.


\chapter{Diskussion}
%TODO hier soll wertend beschrieben werden, was die Resultate bedeuten und wie sich bestimmte Werte erklären lassen
TODO

\section{Bewertung CIGAR-Kodierung}

%Die Abbildungen \ref{fig:cig-bin} und \ref{fig:cig-una} verdeutlichen, dass die binäre und unäre Kodierung deutliche Schwankungen im Bitverbrauch aufweisen, welche sich durch die zufällig generierten Sequenzpaare erklären lassen, deren Alignments unter Umständen sehr viele oder ausschließlich Matches bzw. sehr viele InDels aufweisen können. Die Abbildung \ref{fig:cig-huf} hingegen weist eine Normalverteilung des Bitverbrauchs für die Huffman-Kodierung auf.

%In den dargestellten Testläufen verbraucht die Huffman-Kodierung somit durchschnittlich mit Abstand am wenigsten Speicher, obwohl in dem unter \ref{Cigar_Speicher} beschriebenen Beispiel die unäre Kodierung den CIGAR-String etwas effizienter kodiert. Der Grund hierfür ist die deutlich höhere Fehlerrate in \ref{Cigar_Speicher}, welche die Anzahl der zu kodierenden Symbole deutlich erhöht.

%Das CIGAR-Format benötigt folglich wenig Speicher für Alignments mit einer kleinen Edit-Distanz und deutlich mehr Speicher für Alignments mit einer großen Edit-Distanz, da in diesem Fall eine höhere Anzahl unterschiedlicher Symbole kodiert werden muss.

\section{Bewertung Kodierung der Differenzen der Trace Points}

%Es ist somit zu erkennen, dass die Kodierung der Differenzen der Trace Points mit den oben genannten Parametern der Testläufe in allen Kodierungen weniger Speicher benötigt, als die Kodierung eines CIGAR-Strings, wobei die Huffman-Kodierung mit Abstand am effizientesten ist. Hierbei ist jedoch zu beachten, dass der Speicherverbrauch der Trace Point Kodierung von der Wahl des $\Delta$-Wertes abhängt, da bei einem kleinen $\Delta$ mehr Trace Points und somit mehr Symbole gespeichert werden müssen, als bei einem großen $\Delta$-Wert.

\section{Bewertung Entropie beider Methoden}

%Entropie pro Symbol * #Symbole, daher CIGAR Entropie größer, weil die länger sind

\chapter{Programm}

\section{Aufbau}
\begin{figure}[h]
\begin{tikzpicture}
\begin{class}[text width=7cm]{Cigar Pattern}{0,-15}
\operation{parse\_cigar()}
\operation{combine(cigar)}
\end{class}

\begin{class}[text width=5.5cm]{Alignment}{5,-5.3}
\inherit{Cigar Pattern}
\attribute{seq1 : string}
\attribute{seq2 : string}
\attribute{start\_seq1 : int}
\attribute{end\_seq1 : int}
\attribute{start\_seq2 : int}
\attribute{end\_seq2 : int}
\operation{to\_cigar(seq1, seq2)}
\operation{from\_cigar(seq1, seq2, cigar)}
\operation{show\_aln()}
\end{class}

\begin{class}[text width=5cm]{TracePointAlignment}{-5,-5}
\inherit{Alignment}
\inherit{Cigar Pattern}
\attribute{seq1 : string}
\attribute{seq2 : string}
\attribute{start\_seq1 : int}
\attribute{end\_seq1 : int}
\attribute{start\_seq2 : int}
\attribute{end\_seq2 : int}
\attribute{delta : int}
\attribute{cigar=\textit{None} : string}
\operation{encode()}
\operation{decode()}
\operation{store\_tp\_aln()}
\end{class}

\begin{class}[text width=10.5cm]{Main}{0,0}
\inherit{TracePointAlignment}
\inherit{Alignment}
\operation{random\_sequences(amount,length,error\_rate,alphabet)}
\operation{read\_files(seq\_file, aln\_file)}
\end{class}
\end{tikzpicture}
\caption{UML-Diagramm}
\end{figure}

\clearpage

\section{Funktionalität}

\begin{algorithm}[t]
	\caption{Berechnung der Trace Points von einem gegebenen CIGAR-String}
	\label{encode}
	\noindent\begin{tabular}{@{}l@{~}l}
		\textbf{Parameter}:
		&$seq1$ und $seq2$ sind die beiden Sequenzen mit den jeweiligen Start- \\
		& und Endpositionen $start\_seq1, end\_seq1$ bzw. $start\_seq2, end\_seq2$. \\
		& Zusätzlich werden der Funktion der $\Delta$-Wert und der CIGAR-String \\
		& übergeben.
	\end{tabular}
	\medskip
	\begin{algorithmic}[1]
		\Function{\textit{encode}}{$seq1, seq2, start\_seq1, end\_seq1, start\_seq2, \Delta, cigar$}
		\State assert($\Size{seq1},\Size{seq2},\Size{cigar}, \Delta > 0$)
		\State assert($start\_seq1, start\_seq2 \geq 0$)
		\State assert($start\_seq1 < end\_seq1$)
		\State \Assign{p}{MAX(1, \Roundup{start\_seq1/\Delta})}
		\State \Assign{\tau}{\Roundup{end\_seq1/\Delta} - \Rounddown{start\_seq2/\Delta}}
		\State \Assign{uTP}{\text{Array for interval termini in the first sequence}}
		\For{\Assign{i}{0} \Upto \(\Size{\tau}\)}
		\State \Assign{uTP[i]}{(p + i) \cdot (\Delta - 1)}
			%\begin{cases}
			%	start\_seq1, p \cdot \Delta - 1&\text{ if } i = 0\\
			%	(p + i - 1) \cdot \Delta, (p + i) \cdot \Delta - 1&\text{ if } 0 < i < \Size{\tau}\\
			%	(p + i - 1) \cdot \Delta, end\_seq1 - 1&\text{ else.}
			%\end{cases}}
			\EndFor
			\State \Assign{uChars, vChars, count}{0}
			\State \Assign{TP}{\text{Array for Trace Points}}
			\For{\text{each $(cig\_count, cig\_symbol)$ in cigar}}
			\For{\Assign{i}{0} \Upto \(cig\_count\)}
			\If{cig\_symbol = 'I'}
			\State increment $uChars$
			\ElsIf{cig\_symbol = 'D'}
			\State increment $vChars$
			\Else
			\State increment $uChars, vChars$
			\EndIf
			
			\If{$uChars = uTP[count]$}
			\State $TP$.append($vChars$)
			\EndIf
			\If{$count \neq \Size{uTP} - 1$}
			\State \Return $TP$
			\Else
			\State increment $count$
			\EndIf
			\EndFor
			\EndFor
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	

\subsection{Informationsverlust bei der encode()-Funktion}
	Die encode-Funktion extrahiert aus dem gegebenen CIGAR-String die Trace Points, welche dann zusammen mit dem $\Delta$-Wert und den Start- und Endpositionen der Sequenzabschnitte gespeichert werden. Hierbei geht die Information, wie die jeweiligen Intervalle zwischen den Trace Points zu den komplementären Intervallen in der Ursprungssequenz aligniert werden, verloren.
	Um bestimmen zu können, wie die einzelnen Abschnitte zueinander aligniert werden, muss in der decode()-Funktion zunächst ein neues Alignment des jeweiligen Intervall-Paares errechnet werden und alle Teilalignments zu einem Gesamtalignment konkateniert werden. Hierbei ist jedoch nicht gewährleistet, dass das neue Alignment dem alten entspricht. Da das neue Alignment aus konkatenierten optimalen Alignments besteht, ist es ebenfalls optimal und hat daher mindestens die gleiche Edit-Distanz wie das alte Alignment.
	
	\begin{algorithm}[t]
		\caption{Berechnung eines CIGAR-Strings von einem gegebenen Trace Point Array}
		\label{decode}
		\noindent\begin{tabular}{@{}l@{~}l}
			\textbf{Parameter}:
			&$seq1$ und $seq2$ sind die beiden Sequenzen. \\
			& Zusätzlich werden der Funktion der $\Delta$-Wert und das Trace Point Array \\
			& übergeben.
		\end{tabular}
		\medskip
		\begin{algorithmic}[1]
			\Function{\textit{decode}}{$seq1, seq2, \Delta, TP$}
			\State assert($\Size{seq1}, \Size{seq2}, \Delta, \Size{TP} > 0$)
			\State \Assign{cig}{\text{empty String}}
			\For{\Assign{i}{0} \Upto \(\Size{TP}\)}
			\If{i = 0}
			\State $cig$.append$(\textbf{cigar}(seq1[0...\Delta], seq2[0...TP[i] + 1]))$
			\ElsIf{i = \Size{TP} - 1}
			\State $cig$.append$(\textbf{cigar}(seq1[i \cdot \Delta...\Size{seq1}], seq2[TP[i - 1] + 1...\Size{seq2}]))$
			\Else
			\State $cig$.append$(\textbf{cigar}(seq1[i \cdot \Delta...(i + 1) \cdot \Delta],seq2[TP[i - 1] + 1]...TP[i] + 1))$
			\EndIf
			\EndFor
			\State \Assign{cig}{\textbf{combine}(cig)}
			\State \Return cig
			\EndFunction\\
			
			\Function{\textit{combine}}{$cigar$}
			\State \Assign{cig}{\text{empty String}}
			\State \Assign{tmp}{0}
			\For{\text{each $cig\_count, cig\_symbol$ in cigar}}
			\State \Assign{tmp}{tmp + previous\_cig\_count}
			\If{cig\_symbol = previous\_cig\_symbol}
			\If{\text{not last element in cigar}}
			\State \Assign{tmp}{0}
			\EndIf
			\EndIf
			\If{\text{last element is in cigar}}
			\State $cig$.append$(tmp + cig\_count, cig\_symbol)$
			\EndIf
			\EndFor
			\State \Return cig
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
\chapter{Fazit}

TODO

Je größer der vorher definierte positive Parameter $\Delta$ ist, desto weniger Trace Points werden gespeichert und umso länger dauert die Berechnung, um die Teil-Alignments zu rekonstruieren. Bei einem kleinen $\Delta$ werden analog mehr Trace Points gespeichert, aber die Rekonstruktionszeit der Teil-Alignments ist geringer.

Mithilfe von $\Delta$ lässt sich somit ein Trade-Off zwischen dem Speicherplatzverbrauch und dem Zeitbedarf für die Rekonstruktion der Teil-Alignments einstellen.