\chapter{Einleitung}

Ein Sequenzalignment wird in der Bioinformatik dazu verwendet, zwei oder mehrere Sequenzen zum Beispiel von DNA-Strängen oder Proteinsequenzen miteinander zu vergleichen und die Verwandtschaft zu bestimmen. Ein Alignment ist das Ergebnis eines solchen Vergleichs. Bei einem globalen Alignment wird jeweils die gesamte Sequenz betrachtet, bei einem lokalen Alignment lediglich Teilabschnitte der beiden Sequenzen.

Die effiziente Speicherung der Repräsentation paarweiser Sequenz-Alignments ist von großer Bedeutung, um den Speicherbedarf einer Repräsentation zu verringern. In der Bioinformatik nimmt die Anzahl der zu vergleichenden Sequenzen immer weiter zu. Für viele Sequenzen oder Sequenzabschnitte müssen Alignments gespeichert werden. Um den Speicherbedarf einer solchen Repräsentation zu verringern, ist eine Kodierung sinnvoll. Die zu kodierende Information enthält allgemeine Informationen zu den Sequenzen, etwa die Start- und End-Positionen. Die Sequenzen selber müssen nicht kodiert werden, da sie Teil des Ergebnisses sind.

Ziel dieser Bachelorarbeit ist es, verschiedene Repräsentationen von paarweisen Sequenzalignments und deren Kodierungen zu beschreiben und zu vergleichen, sowie basierend auf einer eigenen Implementierung einer speichereffizienten Repräsentation Unterschiede zu diskutieren.

Die verschiedenen Operationen, um die Symbole der einen Sequenz in die andere zu überführen, können je nach Verfahren unterschiedlich dargestellt und gewichtet werden. Bei Gleichheit wird sie als 'match', bei einer Substitution als 'mismatch', bei einer Löschung als 'deletion' und bei einer Einfügung als 'insertion' dargestellt.

Um die verschiedenen Sequenzen vergleichen zu können, berechnet man für das Alignment einen Score oder die Kosten, um den Aufwand, den man betreiben muss, um die gegebenene Sequenz in die Zielsequenz umzuwandeln, beschreiben zu können. Hierbei wird jeweils das Optimum, also entweder der maximale Score oder die minimalen Kosten gesucht. Ähnliche Sequenzen haben einen hohen Score und geringe Kosten und unterschiedliche Sequenzen analog einen kleinen Score und hohe Kosten.

Das in dieser Arbeit vorgestellte speichereffiziente Verfahren der Trace Points ist als Python- und C-Implementierung in meinem GitHub-Repository (\url{https://www.github.com/thorbenwiese/bachelorarbeit\_wiese.git}) zu finden.

\chapter{Methoden}\label{methoden}

\section*{Die Edit-Operationen}

Die in diesem Kapitel eingeführten Begriffe werden in \cite[S. 5-7, 14-16]{gsa-skript} definiert.

Sei $\mathcal{A}$ eine endliche Menge von Buchstaben, die man Alphabet nennt. Für DNA-Sequenzen verwendet man üblicherweise die Menge der Basen, also $\mathcal{A} = \{a, c, g, t\}$. $\mathcal{A}^i$ sei die Menge der Sequenzen der Länge $i$ aus $\mathcal{A}$ und $\varepsilon$ sei die leere Sequenz. Formal ausgedrückt ist eine Edit-Operation ein Tupel 
\[(\alpha, \beta) \in (\mathcal{A}^1 \cup \{\varepsilon\}) \times (\mathcal{A}^1 \cup \{\varepsilon\}) \backslash \{(\varepsilon, \varepsilon)\}.\]

Eine äquivalente Schreibweise von $(\alpha,\beta)$ ist $\alpha \rightarrow \beta$. Es gibt drei verschiedene Edit-Operationen
\begin{align*}
a \rightarrow \varepsilon &\indent \text{ ist eine Deletion für alle }a \in \mathcal{A}\\
\varepsilon \rightarrow b &\indent \text{ ist eine Insertion für alle }b \in \mathcal{A}\\
a \rightarrow b &\indent \text{ ist eine Substitution für alle }a,b \in \mathcal{A}
\end{align*}
Dabei ist zu beachten, dass $\varepsilon \rightarrow \varepsilon$ keine Edit-Operation darstellt.

Deletionen und Insertionen werden auch Fehler genannt und das Verhältnis der Fehler zur Gesamtanzahl der Edit-Operationen ist die Fehlerrate einer Sequenz.

Ein Alignment von zwei Sequenzen $u$ und $v$ lässt sich nun als eine Sequenz $(\alpha_1 \rightarrow \beta_1, ... , \alpha_h \rightarrow \beta_h)$ von Edit-Operationen definieren, sodass $u = \alpha_1 ... \alpha_h$ und $v = \beta_1 ... \beta_h$ gilt.

Ein Alignment wird in drei Zeilen so geschrieben, dass in der ersten Zeile die Sequenz $u$ und in der dritten Zeile die Sequenz $v$ enthalten ist. In der mittleren Zeile symbolisiert das Zeichen \texttt{'$|$'} einen Match. Außerdem wird ein $\varepsilon$ aus der Edit-Operation durch das Zeichen \texttt{'$-$'} dargestellt.

\begin{bsp}
	Sei von $u$ und $v$ das folgende Alignment $A = (a\rightarrow a, c\rightarrow c, t\rightarrow t, \varepsilon \rightarrow a, g \rightarrow g, a \rightarrow a, a \rightarrow a, c \rightarrow \varepsilon, t \rightarrow t)$ gegeben. 
	\begin{center}
		\texttt{
			\begin{tabular}{ccccccccc}
				a & c & t & - & g & a & a & c & t\\
				$|$&$|$&$|$&&$|$&$|$&$|$& &$|$\\
				a&c&t&a&g&a&a& - &t
			\end{tabular}
		}
	\end{center}
	\label{Bsp1}
\end{bsp}

\section*{Die Edit-Distanz}

Sei eine Kostenfunktion $\delta$ mit $\delta(a\rightarrow b)\geq 0$ für alle Substitutionen $a \rightarrow b$ und $\delta(\alpha \rightarrow \beta)>0$ für alle Einfügungen und Löschungen $\alpha \rightarrow \beta$ gegeben. Die Kosten für ein Alignment $A = (\alpha_1 \rightarrow \beta_1, ... , \alpha_h \rightarrow \beta_h)$ ist die Summe der Kosten aller Edit-Operationen des Alignments.
\[\delta(A) = \sum_{i=1}^{h}\delta(\alpha_i \rightarrow \beta_i)\]
Ein Beispiel einer Kostenfunktion ist die Einheitskostenfunktion
\[
\delta(\alpha \rightarrow \beta) = 
\begin{cases} 
0 ,& \text{wenn } \alpha,\beta \in \mathcal{A} \text{ und } \alpha=\beta \\
1 , & \text{sonst.}
\end{cases}
\]
Die Edit-Distanz von zwei Sequenzen ist wie folgt definiert:
\[edist_\delta(u,v) = \min\{\delta(A) \mid A \text{ ist Alignment von }u \text{ und }v\}\]
Ein Alignment A ist optimal, wenn $\delta(A) = edist_\delta(u,v)$ gilt.\\[0,5cm]
Wenn $\delta$ die Einheitskostenfunktion ist, so ist $edist_\delta(u,v)$ die Levenshtein Distanz \cite[S. 19-21]{gsa-skript}.

Wenn die Edit-Distanz $e$ mit der Einheitskostenfunktion bekannt ist, kann ein optimales lokales Alignment in $O(e^2)$ Zeit berechnet werden \cite{gsa-skript}.%TODO Seite?

\section{Kodierung}

In der Informatik ist eine Kodierung eine Zuweisung von Bits zu jedem Symbol $a$ aus einem Alphabet $\mathcal{A}$. Die Kombination von Bits, die einem Symbol zugeordnet wird, wird Codewort genannt. Eine Kodierung, deren Codewörter nie der Anfang eines anderen Codewortes sind, nennt man einen präfixfreien Code. Dieser hat die Eigenschaft, dass alle Codewörter eindeutig sind und die Dekodierung somit deterministisch ist.

Das effiziente Speichern der Sequenz-Alignments wird durch ihre Kodierung maßgebend beeinflusst. Drei der gängigsten Kodierungsverfahren, die in diesem Kapitel beschrieben werden, sind die unäre Kodierung, die naive binäre Kodierung und die Huffman-Kodierung. 

\subsection{Unäre Kodierung}

Für ein gegebenes Alphabet $\mathcal{A}$ und eine Häufigkeitsverteilung der Symbole aus $\mathcal{A}$ in einer Sequenz $u$ kodiert die unäre Kodierung jedes Symbol in Abhängigkeit von seiner Häufigkeit mit $i - 1$ $'0'$-Bits, gefolgt von einem $'1'$-Bit, wobei $i$ die Position des Symbols in einer nach der Häufigkeit absteigend sortierten Liste ist. Das am Häufigsten auftretende Symbol des Alphabets wird also mit $'1'$, das zweithäufigste mit $'01'$, das dritthäufigste mit $'001'$ usw. kodiert \cite[S. 29-30]{coding}. Diese Art der Kodierung bietet sich insbesondere dann an, wenn ein zu kodierendes Symbol deutlich häufiger auftritt, als die anderen Symbole. Außerdem hat jedes Codewort den Wert $1$, was den Vorteil hat, dass lediglich die Länge variiert. Somit entspricht die Länge eines Codewortes dem Wert, den es kodiert, bzw. die Position in einer nach der Häufigkeit sortierten Liste. Die Gesamtgröße einer unären Kodierung ist somit die Häufigkeit $h(a)$ eines Symbols $a \in \mathcal{A}$, multipliziert mit der Codewortlänge $c(a)$ des Symbols, summiert über alle Symbole.

\[unary(u, \mathcal{A}) = \sum_{a \in \mathcal{A}}^{}h(a) \cdot c(a) \]

\subsection{Naive Binäre Kodierung}

Bei einer naiven binären Kodierung wird jedes Symbol $a$ aus dem Alphabet $\cal{A}$ der zu kodierenden Symbole mit $\lceil \log_2$$|\cal{A}|$$\rceil$ Bit kodiert. Dies hat den Vorteil, dass alle Codewörter die gleiche Länge haben. Diese Art der Kodierung berücksichtigt jedoch lediglich die absolute Anzahl der zu kodierenden Symbole und nicht deren Häufigkeitsverteilung, was eine effiziente Kodierung bei Symbolen mit der selben Häufigkeit ermöglicht, bei einer Abweichung der Häufigkeiten aber keinen Vorteil daraus ziehen kann. Die Größe der Kodierung für eine Sequenz der Länge $n$ berechnet sich somit aus dem Produkt der Anzahl der Symbole, multipliziert mit der Anzahl der benötigten Bits für jedes Symbol.

\[binary(u,\mathcal{A}) = n \cdot \lceil \log_2 |\mathcal{A}|\rceil\]

\subsection{Huffman-Kodierung}

Bei einer \textit{minimalen} binären Kodierung, wie sie auch im Huffman-Alogrithmus verwendet wird, werden die Längen der Codewörter anhand der Häufigkeiten der Symbole in der zu kodierenden Sequenz bestimmt. Hierbei werden häufig vorkommende Symbole durch kurze Codewörter kodiert und weniger häufige durch längere Codewörter. Somit hat die Kodierung im Durchschnitt weniger Bit pro Symbol als etwa die naive binäre Kodierung, bei der die Häufigkeitsverteilung der Symbole nicht berücksichtigt wird. Jedes Codewort ist dabei nie der Anfang eines anderen Codewortes. Das macht den Code präfixfrei, so dass die Codewörter eindeutig zugeordnet werden können \cite[S. 53-57]{coding}.

Als Datenstruktur der zu kodierenden Symbole wird hierbei eine priorisierte Queue $Q$ verwendet, welche nach den Häufigkeiten der Symbole sortiert ist. $Q$ stellt die Operatoren $add$ zum Hinzufügen eines Elements zu $Q$ und $extractmin$ zur Extraktion und Löschung des Elements mit der niedrigsten Priorität zur Verfügung. Falls zwei Elemente die gleiche Priorität haben, wird das in der Alphabetordnung kleinere Symbol extrahiert. 

 Der Huffman-Algorithmus wählt immer die zwei Symbole mit den geringsten Häufigkeiten aus und fügt sie jeweils als ein Symbol zusammen, bis am Ende alle Symbole zusammengefügt wurden. So wird ein Baum mit den kodierten Symbolen als Blätter aufgebaut. Anschließend können durch das Hinzufügen der Kantenbeschriftungen $0$ und $1$ für die ausgehenden Kanten eines Knotens die Kodierungen der einzelnen Symbole durch die Kantenbeschriftungen von der Wurzel aus bis zu den Blättern bestimmt werden. Für die Dekodierung der Codewörter wird somit der Huffman-Baum benötigt, um die Codewörter der Symbole anhand des Pfades von der Wurzel bis zum Blatt bestimmen zu können. Der Pseudocode des Algorithmus ist in Algorithmus 1 dargestellt \cite{fastq-compress}. 

\begin{algorithm}[t]
	\caption{Pseudocode des Huffman-Algorithmus}
	\noindent\begin{tabular}{@{}l@{~}l}
		\textbf{Parameter:}
		& $\cal{A}$ ist das Alphabet der zu kodierenden Symbole mit den Häufigkeiten \\
		& $p(a)$ für alle $a \in \ \mathcal{A}$.\\
		\textbf{Ausgabe:}
		& Der Huffman-Baum des Alphabets $\mathcal{A}$.
	\end{tabular}
	\medskip
	\begin{algorithmic}[1]
		\Function{\textit{Huffman}}{$\mathcal{A} , p: \ \mathcal{A}\ \rightarrow \mathbb{N}$}
		\State assert($\mathcal{|A|} > 0$)
		\State assert($p(a) > 0$)
		\State \Assign{Q}{\emptyset \textit{ als leere priorisierte Queue}}
		\For{\textbf{all} $a \in \mathcal{A}$}
		\State erzeuge neuen Knoten $z$
		\State $(z.\textit{links}, z.\textit{rechts}, z.\textit{char}, z.\textit{count}) = ($nil, nil, $a, p(a))$
		\State $Q.add(z)$
		\EndFor
		\While{$\Size{Q} \geq 2$}
		\State \Assign{x}{Q.extractmin}
		\State \Assign{y}{Q.extractmin}
		\State erzeuge neuen Knoten $z$
		\State \Assign{(z.\textit{links}, z.\textit{rechts})}{(y, x)}
		\State \Assign{z.\textit{char}}{x.\textit{char} < y.\textit{char} \text{ ? } y.\textit{char} \text{ : } x.\textit{char}}
		\State \Assign{z.\textit{count}}{x.\textit{count} + y.\textit{count}}
		\State $Q.add(z)$
		\EndWhile
		\State \Assign{root}{z}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

Eine komprimierte Darstellung einer Kodierung des Huffman-Algorithmus ist ein kanonischer Huffman-Code. Dieser lässt sich aus dem ursprünglichen Huffman-Code erstellen, indem alle Codewörter der selben Länge sequenziell aufsteigende Codewörter erhalten, ohne dass sich die Länge ändert. Aufgrund dieser Eigenschaft wird statt des gesamten Huffman-Baums lediglich die Anzahl der Codewörter für jede vorhandene Codewortlänge, sowie die nach der Codewortlänge sortierten Symbole für die Dekodierung benötigt. Diese zusätzliche Information muss zu der Gesamtgröße der Kodierung hinzuaddiert werden \cite{canonical}.

Die Gesamtanzahl der Bits für die Huffman-Kodierung ergibt sich, wie bei der unären Kodierung, durch das Produkt der Codewortlänge $c(a)$ eines Symbols $a \in \mathcal{A}$ mit der Häufigkeit $h(a)$ des Symbols, aufsummiert über alle Symbole.
\[\mathit{huffman}(u,c,\mathcal{A}) = \sum_{a \in \mathcal{A}}^{}h(a) \cdot c(a) \]

\section{CIGAR-Strings}

Ein Dateiformat, das zur Speicherung von Alignments verwendet wird, ist das SAM-Format oder die binär komprimierte Version BAM. Dieses Format codiert ein Alignment in einem sogenannten CIGAR-String, der aus einzelnen Zeichen besteht, die jeweils eine Edit-Operation bezeichnen. Eine vereinfachte Version der CIGAR-Strings, die in dieser Arbeit verwendet wird, kodiert für eine Substitution ein M, für eine Insertion ein I und für eine Deletion ein D. Gleiche aufeinanderfolgende Operationen werden als Kombination von Quantität und Symbol geschrieben. Die Sequenzen selbst werden hierbei nicht mit kodiert, sondern lediglich die Edit-Operationen auf den Sequenzen.

\begin{defi}
Ein CIGAR-String $C = c_1s_1c_2s_2...c_ns_n$ besteht aus Symbolen $s \in \{$M$,$I$,$D$\}$ und positiven ganzen Zahlen $c_i$. $\qedsymbol$
\end{defi}

Ein CIGAR-String beschreibt ein Alignment, da mit $c_1$ Edit-Operationen vom Typ $s_1$ beginnt, gefolgt von $c_2$ Edit-Operationen vom Typ $s_2$ und so weiter. Dabei wird keine Information über die alignierten Sequenzen mitkodiert. Ein CIGAR-String kann daher verschiedene Alignments repräsentieren.

\begin{bsp}
Sei folgendes Alignment aus Beispiel \ref{Bsp1} gegeben.
\begin{center}
	\texttt{
		\begin{tabular}{ccccccccc}
			a & c & t & - & g & a & a & c & t\\
			$|$&$|$&$|$&&$|$&$|$&$|$& &$|$\\
			a&c&t&a&g&a&a& - &t
		\end{tabular}
	}
\end{center}
Dieses Alignment wird duch den CIGAR-String \texttt{3M1I3M1D1M} repräsentiert \cite{sam}.
\end{bsp}

\subsection{Kodierung eines CIGAR-Strings}\label{Cigar_Speicher}

Für die Kodierung eines CIGAR-Strings ist es sinnvoll, die Quantitäten und Symbole seperat zu kodieren, um so mit kleineren Alphabeten arbeiten zu können.

$\mathcal{A}_s = \{$M$, $I$, $D$\}$ und $\mathcal{A}_c = \{s_i \mid 1 \leq i \leq n\}$ sind somit die Alphabete der zu kodierenden Symbole eines CIGAR-Strings.

Im Folgenden vergleiche ich ausführlich für den CIGAR-String eines Alignments die Verfahren der naiven binären Kodierung, der unären Kodierung und der Huffman-Kodierung.

\FloatBarrier

\begin{bsp}
Sei das Alignment $A$

\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0   
\end{verbatim}
gegeben, welches durch den CIGAR-String\\
\texttt{4M1I1M1I1M1I1M2D1M1D1M1I8M1D7M1D5M1I4M} der Länge $19$ repräsentiert werden kann.

Aus dem CIGAR-String ergibt sich das Alphabet $\mathcal{A}_c = \{1, 2, 4, 5, 7, 8\}$.

Bei einer naiven binären Kodierung wird jedes Symbol aus $\mathcal{A}_{c}$ mit $\lceil \log_26\rceil$ Bit kodiert. Für das Alphabet $\mathcal{A}_s$ gilt, dass das erste Symbol mit $\lceil \log_23\rceil = 2$ Bit und jedes darauf folgende mit lediglich einem Bit kodiert werden kann, da niemals zwei gleiche Symbole aufeinander folgen können und es somit nur zwei Optionen für ein Nachfolgendes Symbol gibt.

Insgesamt benötigt die naive binäre Kodierung somit $19 \cdot \lceil \log_26\rceil + \lceil \log_23\rceil + 18 = 77$ Bit für die Kodierung des CIGAR-Strings.

Die unäre Kodierung des oben genannte CIGAR-Strings ist in Tabelle \ref{cigar-unary} beschrieben. Sie benötigt $32 + 35 = 67$ Bit.

\begin{table}[t]
	\centering
	\begin{tabular}{crcr}
		Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
		\hline
		M & $10$ & $1$ & $10 \cdot 1 = 10$\\
		D & $5$ & $01$ & $5 \cdot 2 = 10$\\
		I & $4$ & $001$ & $4 \cdot 3 = 12$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$32$\\
		&&
	\end{tabular}
	
	\begin{tabular}{crcr}
	Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
	\hline
	$1$ & $13$ &$1$ & $13 \cdot 1 = 13$\\
	$4$ & $2$ &$01$ & $2 \cdot 2 = \ \ 4$\\
	$2$ & $1$ &$001$ & $1 \cdot 3 =\ \ 3$\\
	$5$ & $1$ &$0001$ & $1 \cdot 4 =\ \ 4$\\
	$7$ & $1$ &$00001$ & $1 \cdot 5 =\ \ 5$\\
	$8$ & $1$ &$000001$ & $1 \cdot 6 =\ \ 6$\\
	\hline
	\multicolumn{3}{l}{Gesamtanzahl:}&$35$
\end{tabular}
\caption{Unäre Kodierung des CIGAR-Strings}
\label{cigar-unary}
\end{table}

Der kanonische Huffman-Algorithmus würde bei dem oben genannten Beispiel des CIGAR-Strings nach \cite[S. 54]{coding} die Symbole wie in Tabelle \ref{cig-huf-coding} beschrieben kodieren. Die Huffman-Bäume beider Alphabete sind in Abbildung \ref{Huff-Tree-Cig} dargestellt. Für die Dekodierung sind somit zusätzlich die Listen $(1,2),($M$, $D$, $I$)$ und $(1,1,0,4),(1,4,2,5,7,8)$ zu speichern. Diese können als sogenannter 'Header' am Anfang der kodierten Datei unär kodiert werden. In diesem Fall würde der Header als $01001\ 0001$ und $0101100001\ 0000001$ kodiert werden, wobei jeweils der erste Teil die Häufigkeiten der Code-Längen und der zweite Teil die Gesamtanzahl der Symbole kodiert.

Die Größe dieser Kodierung ist demnach $28 + 33 + 9 + 17 = 87$ Bit.

\begin{table}[t]
	\centering
	\begin{tabular}{crcr}
		Symbol & Häufigkeit & Kodierung & Anzahl Bits\\
		\hline
		M & $10$ &$0$ & $10 \cdot 1 = 10$\\
		D & $5$ &$10$ & $5 \cdot 2 = 10$\\
		I & $4$ &$11$ & $4 \cdot 2 =\ \ 8$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$28$\\
		&&&
	\end{tabular}
	
	\begin{tabular}{crcr}
	Symbol & Häufigkeit & Kodierung & Anzahl Bits\\
	\hline
	$1$ & $13$ & $0$ & $13 \cdot 1 = 13$\\
	$4$ & $2$ & $10$ & $2 \cdot 2 =\ \ 4$\\
	$2$ & $1$ & $1100$ & $1 \cdot 4 =\ \ 4$\\
	$5$ & $1$ & $1101$ & $1 \cdot 4 =\ \ 4$\\
	$7$ & $1$ & $1110$ & $1 \cdot 4 =\ \ 4$\\
	$8$ & $1$ & $1111$ & $1 \cdot 4 =\ \ 4$\\
	\hline
	\multicolumn{3}{l}{Gesamtanzahl:}&$33$
\end{tabular}
\caption{Huffmann-Kodierung des CIGAR-Strings}
\label{cig-huf-coding}
\end{table}

\begin{figure}[t]
	\centering
	\begin{forest}
		for tree={grow'=south}
		[$19$
		[$9$, edge label={node[midway,right,font=\scriptsize]{1}}
		[I, edge label={node[midway,right,font=\scriptsize]{1}}]
		[D, edge label={node[midway,left,font=\scriptsize]{0}}] ] 
		[M, edge label={node[midway,left,font=\scriptsize]{0}}] ]
		]
	\end{forest}
	\begin{tabular}{ccc}
		&&
	\end{tabular}
	\begin{forest}
		for tree={grow'=south}
		[$19$
		[$6$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$4$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$2$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$8$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$7$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$2$, edge label={node[midway,left,font=\scriptsize]{0}}
		[$5$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$2$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]]
		[$4$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$1$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]
	\end{forest}
	\caption{Huffman-Bäume für die Häufigkeitsverteilung der Symbole des CIGAR-Strings}
	\label{Huff-Tree-Cig}
\end{figure}
\label{Alignment-bsp}
\end{bsp}

\section{Das Trace Point Konzept} \label{TP Konzept}

Ein neuer Ansatz der speichereffizienten Repräsentation von Alignments wurde von Gene Myers in \cite{myers} beschrieben und basiert auf dem Konzept der Trace Points.

Der Grundgedanke dieser Methode ist es, das Alignment zweier gegebener Sequenzen nicht als solches kodiert abzuspeichern, sondern stattdessen die erste Sequenz in gleich große Abschnitte der Länge $\Delta$ zu unterteilen und die Endpunkte, sogenannte Trace Points, von Teilabschnitten des Alignments in der zweiten Sequenz abzuspeichern. Zur Rekonstruktion eines Gesamtalignments wird für jeden Teilabschnitt jeweils ein Teilalignment berechnet. Die Teilalignments können dann zu einem Gesamtalignment konkateniert werden.

Das Verfahren bietet den Vorteil, durch die Größe $\Delta$ der Teilabschnitte die Anzahl der Trace Points und somit den Speicherbedarf, sowie die Zeit, die für die Berechnung der Teilalignments benötigt wird, anpassen zu können.

Sei $A$ ein Alignment von $u[i...j]$ und $v[k...\ell]$ mit $i < j$ und $k < \ell$ und sei $\Delta \in \mathbb{N}$. Sei außerdem $p$ wie folgt definiert:
\[ p = \begin{cases}
\left \lceil\frac{i}{\Delta}\right \rceil & \text{falls } i > 0\\
1 & \text{falls }i = 0.
\end{cases}\]

Man unterteilt $u[i...j]$ in $\tau = \left \lceil\frac{j}{\Delta}\right \rceil - \left \lfloor\frac{i}{\Delta}\right \rfloor$ Substrings $u_0, u_1, ... , u_{\tau -1}$ mit
\[  
u_q =
\begin{cases} 
u[i...p\cdot\Delta] & \text{falls }q = 0 \\
u[(p+q-1)\cdot\Delta+1...(p+q)\cdot\Delta] & \text{falls }0<q<\tau -1\\
u[(p+\tau-2)\cdot\Delta...j] & \text{falls }q = \tau -1
\end{cases}
\]

Für alle $q$ mit $ 0 \leq q < \tau -1$ sei $t_q$ der letzte Index des Substrings von $v$, der in A mit $u_q$ aligniert. $t_q$ nennt man Trace Point. Für $q = 0$ aligniert $u_0$ mit $v_0 = v[k...t_0]$. Für alle $q$ mit $0<q< \tau -1$ aligniert $u_q$ mit $v_q = v[t_{q-1}+1...t_q]$.

Jedes Paar von zu alignierenden Substrings mit der Einheitskosteneditdistanz $e$ kann in $O(e^2)$ Zeit berechnet werden. Für eine erwartete Fehlerrate von $\varepsilon$ gilt dann $e \leq \varepsilon\Delta$. Die Konkatenation der Teilalignments hat somit höchstens die Kosten des Alignments der Gesamtsequenz \cite[S. 41-42]{gsa-skript}.

Seien $i,j,k,\ell,\Delta$ und die Trace-Points eines Alignments von $u$ und $v$ gegeben. Dann kann man ein Alignment $A'$ von $u$ und $v$ mit $\delta (A') \leq \delta (A)$ konstruieren. Dann bestimmt man aus den Trace-Points die Substring-Paare $u_q$ und $v_q$ für alle $q, 0 \leq q \leq \tau - 1$, berechnet hierfür jeweils ein optimales Alignment und konkateniert die Alignments von den aufeinanderfolgenden Substring-Paaren zu $A'$.
%TODO Seitenumbruch
\clearpage
\begin{bsp}

Sei $u = u[0...37]$ und $v = v[0...37]$ und das folgende Alignment gegeben:

\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0    
\end{verbatim}

Sei $i = k = 0$ und $j = \ell = 37$ und $\Delta = 15$. Das Alignment wird in $\tau = \left \lceil\frac{37}{15}\right \rceil - \left \lfloor\frac{0}{15}\right \rfloor = 3 - 0 = 3$ Abschnitte unterteilt. Der erste Abschnitt aligniert $u[0...14]$ und $v[0...15]$.
\begin{verbatim}
gagc-a-t-gttgcc-tgg
|| | | | |  | | |||
gaccaagtag--g-cgtgg
\end{verbatim}
Der zweite Abschnitt aligniert $u[15...29]$ und $v[16...28]$.
\begin{verbatim}
tcctttgctaggtac
|||| ||| ||| |
acctt-gctcggt-c
\end{verbatim}
Der dritte Abschnitt aligniert $u[30...37]$ und $v[29...37]$.
\begin{verbatim}
tgta-gaga
|||| ||||
tgtaagaga
\end{verbatim}
Somit ergeben sich als Endpunkte aller Abschnitte außer dem letzten Abschnitt die Trace Points $15$ und $28$.
\end{bsp}

\subsection{Differenzen-Kodierung}\label{Differenzen-Kodierung}

Gegeben sei eine Liste $L = (a_1, a_2, ... , a_n)$ mit $a_i < a_{i+1}, 1 \leq i < n$.

Anstatt jeden Wert in $L$ als solchen abzuspeichern, kann alternativ die Differenz eines Wertes $a_i$ zu dem nachfolgenden Wert $a_{i+1}$ abgespeichert werden. Lediglich der erste (oder letzte) Wert aus $L$ wird benötigt, um später sukzessive die ursprüngliche Liste rekonstruieren zu können. Wir definieren daher
\[L_{\mathit{diff}} = (a_1, (a_2-a_1), (a_3-a_2), ... , (a_{n}-a_{n-1}))\]

Bei gleichmäßig ansteigenden Werten ist die Abweichung der Differenzen zweier aufeinanderfolgender Werte in der Liste untereinander gering und die Menge der zu kodierenden Symbole ist klein.

Im folgenden Beispiel werde ich die Kodierung der Trace Point Differenzen ausführlich für die naive binäre, unäre und Huffman-Kodierung erläutern.

\begin{bsp}
Sei $\Delta = 5$ und das Alignment $A$
\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0   
\end{verbatim}

wie in Abschnitt \ref{Cigar_Speicher} mit den dazugehörigen TracePoints $L = (5, 10, 15, 20, 24, 28, 34)$ gegeben.

Für die Kodierung der Trace Points ist in diesem Beispiel somit eine Differenzen-Kodierung sinnvoll.

Daher ergibt sich $L_{\mathit{diff}} = (5, 5, 5, 5, 4, 4, 6)$.

Um aus den Trace Points ein neues Alignment rekonstruieren zu können, benötigt man zusätzlich mindestens den $\Delta$-Wert, sowie die Start- und End-Positionen der Sequenzen die aligniert werden, damit die Grenzen der Substrings beider Sequenzen berechnet werden können. Hierfür kann der $\Delta$-Wert zu $L_{\mathit{diff}}$ hinzugefügt werden, da er bei $\Delta$ großen Teilabschnitten in $u$ wahrscheinlich der dominierende Wert in $L_{\mathit{diff}}$ sein wird.

Für das oben genannten Beispiel ergibt sich somit
\begin{center}
\begin{tabular}{rcl}
	$L_{\mathit{diff}}$ &$=$& $(\Delta, a_1, (a_2-a_1), (a_3-a_2), ... , (a_{n}-a_{n-1}))$\\
	&$=$ & $(5, 5, 5, 5, 5, 4, 4, 6)$
\end{tabular}
\end{center}

sowie das Alphabet $\mathcal{A} = \{4, 5, 6\}$ mit den Häufigkeiten aus Tabelle \ref{diff-unary}. 

Bei der naiven binären Kodierung von $L_{\mathit{diff}}$ ergibt sich analog zu \ref{Cigar_Speicher} ein Bedarf von $\lceil \log_28\rceil = 3$ Bit pro Symbol, also $8 \cdot 3 = 24$ Bit insgesamt und damit nur  $\frac{24}{77} = 31.17$\% der Größe der naiven binären Kodierung für den CIGAR-String.

Die unäre Kodierung ergibt für dieses Beispiel die in Tabelle \ref{diff-unary} beschriebene Kodierung. Die Größe dieser Kodierung ist demnach $12$ Bit und benötigt damit nur $\frac{12}{67} = 17.91$\% der unären Kodierung für den CIGAR-String.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
		\hline
		$5$ & $5$ &$0$ & $5 \cdot 1 = 5$\\
		$4$ & $2$ &$10$ & $2 \cdot 2 = 4$\\
		$6$ & $1$ &$110$ & $1 \cdot 3 = 3$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$12$
	\end{tabular}
	\caption{Unäre Kodierung von $L_{\mathit{diff}} = (5, 5, 5, 5, 4, 4, 6)$ und $\Delta = 5$}
	\label{diff-unary}
\end{table}

Der Huffman-Algorithmus kodiert nach \cite[S. 54]{coding} die Symbole wie in Tabelle \ref{Diff-Huff} aufgelistet. Der dazugehörige Huffmann-Baum aus \ref{Huff-Tree-Diff} verdeutlicht die Kodierung der einzelnen Symbole, muss aber für den kanonischen Huffman-Algorithmus, wie in \ref{Cigar_Speicher} beschrieben, nicht komplett gespeichert werden. Aufgrund der Beschaffenheit der Codewörter des kanonischen Huffman-Algorithmus ist hier lediglich die Speicherung der Listen $(1,2),(5,4,6)$, welche als $01001;0001$ im Header kodiert werden, nötig.

Die Größe der kanonischen Huffman-Kodierung ist demnach $11 + 9 = 20$ Bit und benötigt damit nur $\frac{20}{87} \approx 23$\% der Huffman-Kodierung für den CIGAR-String.

\begin{table}
	\centering
	\begin{tabular}{ccr}
		Symbol & Kodierung & Anzahl Bits\\
		\hline
		$5$ & $0$ & $5 \cdot 1 = 5$\\
		$4$ & $10$ & $2 \cdot 2 = 4$\\
		$6$ & $11$ & $1 \cdot 2 = 2$\\
		\hline
		\multicolumn{2}{l}{Gesamtanzahl:}&$11$
	\end{tabular}
	\caption{Huffman-Kodierung von $L_{\mathit{diff}} = (5, 5, 5, 5, 4, 4, 6)$ und $\Delta = 5$}
	\label{Diff-Huff}
\end{table}

\begin{figure}
	\centering
	\begin{forest}
		for tree={grow'=south}
		[$8$
		[$3$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$6$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$4$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$5$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]
	\end{forest}
	\caption{Huffman-Baum der Differenzen-Kodierung}
	\label{Huff-Tree-Diff}
\end{figure}
\end{bsp}

\section{Entropie der Methoden}\label{entropie-der-methoden}

Sei $S$ eine Sequenz der Länge $n$ in der die Symbole $a \in \mathcal{A}$ mit der Häufigkeit $h(a)$ auftreten. Die Entropie $H(S)$ beschreibt den durchschnittlichen Informationsgehalt für alle Symbole aus $S$ in der Einheit $\frac{\text{Bit}}{\text{Symbol}}$.
\[H(S) = - \sum_{a \in S}h(a) \cdot \log_2h(a)\]
Sie ist maximal, wenn $h(a) = h(b)$ für jeweils zwei verschiedene Symbole $a,b \in \mathcal{A}$ gilt \cite{entropy}.

Für den in \ref{Cigar_Speicher} genannten CIGAR-String $S$ mit der Häufigkeitsverteilung aus Tabelle \ref{diff-unary} ergibt sich eine Entropie von

\begin{center}
\begin{tabular}{rcl}
	$H(\mathit{Cigar})$ &$=$& $-(\frac{10}{38} \cdot \log_2\frac{10}{38} + \frac{5}{38} \cdot \log_2\frac{5}{38} + \frac{4}{38} \cdot \log_2\frac{4}{38} + \frac{13}{38} \cdot \log_2\frac{13}{38} + \frac{2}{38} \cdot$\\
	&&$\log_2\frac{2}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38})$\\
	&$\approx$& $2.54\ \frac{\text{Bit}}{\text{Symbol}}$
\end{tabular}
\end{center}

und somit eine Gesamtentropie von $2.54 \cdot 38 = 96.52$ Bit.

Die in \ref{Differenzen-Kodierung} genannten Trace Point Differenzen des selben Alignments inklusive des $\Delta$-Wertes ergeben analog

\begin{center}
\begin{tabular}{rcl}
	$H(\mathit{L_{diff}})$ &$=$& $-(\frac{5}{8} \cdot \log_2\frac{5}{8} + \frac{2}{8} \cdot \log_2\frac{2}{8} + \frac{1}{8} \cdot \log_2\frac{1}{8})$\\
	&$\approx$& $1.30\ \frac{\text{Bit}}{\text{Symbol}}$
\end{tabular}
\end{center}

und somit eine Gesamtentropie von $1.30 \cdot 8 = 10.4$ Bit.

Zusammenfassend ergibt sich für die Größen der Kodierungen des Alignments aus Beispiel \ref{Bsp1} Tabelle \ref{Kodierung-Tabelle}.
\begin{table}[t]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		&CIGAR-String&Trace Point Differenzen\\
		\hline
		Binäre Kodierung&$77$&$24$\\
		\hline
		Unäre Kodierung&$67$&$12$\\
		\hline
		Huffman-Kodierung&$87$&$21$\\
		\hline
		Entropie&$96.52$&$10.4$\\
		\hline
	\end{tabular}
	\caption{Anzahl der Bits für die Kodierung des Beispiel-Alignments}
	\label{Kodierung-Tabelle}
\end{table}

\chapter{Implementierung}

Die Umsetzung des Trace Point Verfahrens, sowie die Berechnung der verschiedenen Größen der Kodierung ist im Rahmen dieser Arbeit zunächst in Python und anschließend als C-Implementierung realisiert worden. 

Die Implementierung besteht aus dem Main-Modul, welches als Eingabeparameter die Sequenzen, deren Start- und Endpositionen, sowie den $\Delta$-Wert entgegennimmt und diese in einer 'Trace Point Liste' speichert. Anschließend wird mithilfe eines dynamischen Programmieralgorithmus' ein optimales lokales Alignment der zu alignierenden Teilabschnitte der Sequenzen erzeugt und als Liste von Edit-Operationen gespeichert. Die Trace Point Liste und die Liste der Edit-Operationen werden dann an die encode-Funktion übergeben, die in einem eigenen TracePoint-Modul definiert ist.

Diese Funktion unterteilt die Sequenzen wie in Kapitel \ref{TP Konzept} beschrieben und bestimmt die Trace Points, welche dann ebenfalls in der Trace Point Liste gespeichert werden. Der Pseudocode der encode-Funktion ist in Algorithmus \ref{encode} beschrieben. Hierbei geht die Information, wie die jeweiligen Intervalle zwischen den Trace Points zu den komplementären Intervallen in der Ursprungssequenz aligniert werden, verloren. Es sind also lediglich die zu alignierenden Abschnitte bekannt, aber nicht die Alignierung selber. Diese muss bei der Dekodierung neu berechnet werden.

Die Dekodierung der Trace Points erfolgt in der decode-Funktion, welche ebenfalls im TracePoint-Modul definiert ist. Sie nimmt eine Trace Point Liste als Parameter entgegen und berechnet für jedes Paar von zu alignierenden Teilabschnitten eine neue Liste von Edit-Operationen und konkateniert diese abschließend zu einer Gesamtliste und gibt sie als Rückgabewert zurück. Der Pseudocode der decode-Funktion ist in Algorithmus \ref{decode} zu finden. Hierbei ist nicht gewährleistet, dass das neue Alignment dem alten entspricht. Das neue Alignment hat jedoch, wie in \ref{TP Konzept} beschrieben, keine höheren Kosten als das Ausgangsalignment.

Der Aufbau der Implementierung ist als UML-Klassendiagramm in Abbildung \ref{UML} dargestellt. Die im Rahmen dieser Arbeit von mir implementierten Module belaufen sich dabei auf die dargestellten Klassen Main und TracePoint. Die Alignment-Klasse wurde von Prof. Dr. Stefan Kurtz bereitgestellt, um einen dynamischen Programmieralgorithmus für die Berechnung von Alignments in Form von Edit-Operations-Listen nutzen zu können.

\begin{algorithm}[t]
	\caption{Berechnung der Trace Points aus einer gegebenen Liste von Edit-Operationen}
	\label{encode}
	\noindent\begin{tabular}{@{}l@{~}l}
		\textbf{Parameter}:
		& Der Funktion wird eine Referenz auf eine Trace Point Liste $*tp\_list$ und \\
		& eine Referenz auf die Liste der Edit-Operationen $*eoplist$ übergeben.
	\end{tabular}
	\medskip
	\begin{algorithmic}[1]
		\Function{\textit{encode}}{$*tp\_list, *eoplist$}
		\State assert($tp\_list.start1, tp\_list.start2 \geq 0$)
		\State assert($tp\_list.start1 < tp\_list.end1$)
		\State \Assign{p}{MAX(1, \Roundup{start1/\Delta})}
		\State \Assign{\tau}{\Roundup{end1/\Delta} - \Rounddown{start1/\Delta}}
		\State \Assign{uTP}{\text{Array of length $\tau + 1$ for interval termini in first sequence}}
		\For{\Assign{q}{0} \Upto $\tau$}
		\State \Assign{uTP[q]}{(p + q) \cdot \Delta - 1}
		\EndFor
		\State \Assign{uChars, vChars, count}{0}
		\State \Assign{TP}{\text{Array of length $\tau - 1$ of Trace Points}}
		\For{\textbf{each} \text{Operation in eoplist}}
		\For{\Assign{i}{0} \Upto \(eop\_count - 1\)}
		\If{$eop\_type$ = 'Insertion'}
		\State increment $uChars$
		\ElsIf{$eop\_type$ = 'Deletion'}
		\State increment $vChars$
		\Else
		\State increment $uChars, vChars$
		\EndIf
		\If{$uChars = uTP[count]$}
		\State $tp\_list.TP$.append($vChars$)
		\EndIf
		\If{$count = \tau - 1$}
		\State \textbf{\textit{break}}
		\Else
		\State increment $count$
		\EndIf
		\EndFor
		\EndFor
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
	\caption{Berechnung einer Liste von Edit-Operationen aus einer gegebenen Trace Point Liste}
	\label{decode}
	\noindent\begin{tabular}{@{}l@{~}l}
		\textbf{Parameter:}
		& Der Funktion wird eine Referenz auf eine Trace Point Liste $*tp\_list$ \\
		& übergeben. \\
		\textbf{Ausgabe:}
		& Die Funktion liefert eine konkatenierte Liste von Edit-Operationen \\
		& zurück.
	\end{tabular}
	\medskip
	\begin{algorithmic}[1]
		\Function{\textit{decode}}{$*tp\_list$}
		\State \Assign{eoplist }{\text{empty list of edit operations}}
		\For{\Assign{k}{0} \Upto \(tp\_list.TP\_len - 1\)}
		\If{k = 0}
		\State \Assign{sub\_eoplist}{opt\_align(seq1[0...\Delta], seq2[0...tp\_list.TP[k] + 1])}
		\ElsIf{k = \Size{TP} - 1}
		\State \Assign{sub\_eoplist}{opt\_align(seq1[k \cdot \Delta...\Size{seq1}],}
		\State \hspace{4.25cm} $\ \ seq2[tp\_list.TP[k - 1] + 1...\Size{seq2}])$
		\Else
		\State \Assign{sub\_eoplist}{opt\_align(seq1[k \cdot \Delta...(k + 1) \cdot \Delta],}
		\State \hspace{4.25cm} $\ \ seq2[tp\_list.TP[k - 1] + 1]...$
		\State \hspace{5.4cm} $tp\_list.TP[k] + 1)$
		\EndIf
		\State $eoplist.append(sub\_eoplist)$	
		\EndFor
		\State \Return $eoplist$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{figure}[t]
	\begin{tikzpicture}
	
	\begin{class}[text width=8.5cm]{Alignment}{4,-5}
	\operation{calculate\_edit\_operation\_list(Trace Point list)}
	\end{class}
	
	\begin{class}[text width=8.5cm]{TracePoint}{4,-1}
	\inherit{Alignment}
	\attribute{Trace Point List}
	\operation{encode(Trace Point List, Edit-Operation List)}
	\operation{decode(Trace Point List)}
	\end{class}
	
	\begin{class}[text width=5cm]{Main}{-5,-2.5}
	\attribute{Sequenz 1, Sequenz 2}
	\attribute{Start 1, End 1}
	\attribute{Start 2, End 2}
	\attribute{$\Delta$}
	\inherit{TracePoint}
	\inherit{Alignment}
	\operation{create\_Trace\_Point\_List()}
	\end{class}
	\end{tikzpicture}
	\caption{UML Klassendiagramm der Implementierung des Trace Point Konzepts}
	\label{UML}
\end{figure}

\chapter{Resultate} \label{Resultate}

Die Verfahren, um die in diesem Kapitel beschriebenen Größen der Kodierungen zu berechnen, wurden in Python implementiert. Die Messung der Zeit für die Rekonstruktion der Teilalignments erfolgte mit den gleichen Daten mit einer C-Implementierung. Für die Messungen wurde ein MacBook Pro 11.1 mit macOS Sierra 10.12.1, einem 2.4 GHz Intel Core i5 Prozessor und 4 GB Arbeitsspeicher verwendet.

\section{Kodierung der CIGAR-Strings}

Für die empirische Untersuchung der Größe der einzelnen Kodierungen wurden die verschiedenen Kodierungen für jeweils CIGAR-Strings und Trace Point Differenzen mit unterschiedlichen Parametern, sowie die Verteilung der Entropie der zwei Verfahren berechnet und grafisch dargestellt. Hierfür wurden DNA-Sequenzen aus zufällig aneinander gereihten Basen und daraus abgewandelte Sequenzen mit der jeweiligen Fehlerrate durch Austauschen oder Löschen bzw. Einfügen von Basen berechnet. Aus jedem Sequenzpaar wurde dann ein optimales Alignment als Liste von Edit-Operationen berechnet und als CIGAR-String konvertiert. Dieser konnte dann mit den oben beschriebenen Verfahren kodiert und die Größe der Kodierung bestimmt werden.

Die gemessenen Werte der Größe der Kodierung der CIGAR-Strings sind in Tabelle \ref{bits-result} enthalten und die Häufigkeitsverteilung der Kodierung für \numprint{1000} CIGAR-Strings mit je \numprint{5000} Basenpaaren und einer Fehlerrate von $15$\% ist in Abbildung \ref{cigar-coding} grafisch dargestellt.

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{images/data/cigar}
	\caption{Häufigkeitsverteilung der Kodierungen für \numprint{1000} CIGAR-Strings von DNA Sequenzen mit je \numprint{5000} Basenpaaren und einer Fehlerrate von $15$\%.} \label{cigar-coding}
\end{figure}

\section{Kodierung der Trace Point Differenzen}
Für die Kodierung der Trace Point Differenzen wurden die Trace Points anhand des $\Delta$-Wertes aus der Liste der Edit-Operationen berechnet und die Differenzen der Trace Points bestimmt. Diese wurden dann mit den oben beschriebenen Verfahren kodiert und dabei die Größe der Kodierung bestimmt. Außerdem wurde die Zeit, die für die Dekodierung der Trace Points zu einer Liste von Edit-Operationen benötigt wird, gemessen.

Für die binäre Kodierung der Trace Point Differenzen werden bei einem $\Delta$-Wert von $200$ bei jedem Durchlauf für $24$ Trace Points und den $\Delta$-Wert selbst insgesamt $\lceil \log_225$$\rceil = 125$ Bit benötigt.

Die Größe der unären und Huffman-Kodierung der Trace Point Differenzen für \numprint{1000} Sequenzen mit je \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $200$ und einer Fehlerrate von $15$\% sind in Tabelle \ref{bits-result} beschrieben und in Abbildung \ref{tracepoint-d200} dargestellt. Die Abhängigkeit der Größe der Kodierung von $\Delta$ ist in Abbildung \ref{var-deltas} zu erkennen und die Auswirkungen der Fehlerrate sind in Abbildung \ref{var-errs} grafisch dargestellt. Die Größen der Kodierungen in Abhängigkeit beider Parameter ist in Tabelle \ref{var-errs-deltas} beschrieben.

Um die Zeit, die für die Rekonstruktion der Teilalignments in Abhängigkeit von $\Delta$ benötigt wird, berechnen zu können, wurden für $\Delta$-Werte im Bereich von $5$ bis $500$ jeweils $50$ Sequenzpaare der Länge \numprint{5000} mit einer Fehlerrate von $15$\% wie oben beschrieben berechnet und die Trace Point Differenzen berechnet, anschließend dekodiert und die Zeit dafür gemessen. Diese Dekodierung entspricht der Rekonstruktion der Teilalignments und der anschließenden Konkatenation zu einem Gesamtalignment. Die Resultate sind in Tabelle \ref{time-table} beschrieben und in Abbildung \ref{time} grafisch dargestellt.

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{images/data/tracepoint}
	\caption{Häufigkeitsverteilung der Kodierungen der Trace Point Differenzen für \numprint{1000} DNA-Sequenzen mit je \numprint{5000} Basenpaaren, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $200$.} \label{tracepoint-d200}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{images/data/delta-rate}
	\caption{Mittelwerte der Huffman-Kodierung der Trace Point Differenzen für \numprint{5000} Basenpaaren, einer Fehlerrate von $15$\% und $\Delta$-Werten von $5$ bis $500$.} \label{var-deltas}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{images/data/err-rate}
	\caption{Mittelwerte der Huffman-Kodierung der Trace Point Differenzen für \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $100$ und Fehlerraten von $5$\% bis $35$\%.} \label{var-errs}
\end{figure}

\FloatBarrier
\begin{table}[t]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		&\multicolumn{3}{c|}{CIGAR-String}&\multicolumn{3}{c|}{Trace Point Differenzen ($\Delta = 200$)}\\
		&Min&Max&$\diameter$&Min&Max&$\diameter$\\
		\hline
		Binäre Kodierung&\numprint{4480}&\numprint{9100}&\numprint{6595}&125&125&125\\
		\hline
		Unäre Kodierung&\numprint{3500}&\numprint{5100}&\numprint{4290}&60&132&90\\
		\hline
		Huffman-Kodierung&\numprint{1300}&\numprint{1625}&\numprint{1458}&42&126&84\\
		\hline
		Entropie&\numprint{1280}&\numprint{2280}&\numprint{1755}& 91&212&134\\
		\hline
	\end{tabular}
	\caption{Größe der Kodierungen und Entropie in Bit}
	\label{bits-result}
\end{table}

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{images/data/time}
	\caption{Zeitbedarf der Rekonstruktion der Teilalignments für jeweils \numprint{5000} Sequenzpaare mit je \numprint{5000} Basen, einer Fehlerrate von $15$\% und verschiedenen $\Delta$-Werten}
	\label{time}
\end{figure}

\begin{table}[t]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		& \multicolumn{2}{c|}{$\Delta$} & \multicolumn{2}{c|}{Fehlerrate} \\
		\hline
		Wert & $35$ & $500$ &  $5$\% & $35$\% \\
		\hline
		Größe & $95$ & $76$& $44$ & $97$ \\
		\hline
	\end{tabular}
	\caption{Größe der Kodierung für verschiedene $\Delta$-Werte und Fehlerraten}
	\label{var-errs-deltas}
\end{table}

\begin{table}[t]
	\centering
	\begin{tabular}{|c|r|}
		\hline
		$\Delta$ & Zeit in Sekunden \\
		\hline
		$5$ & $4.38$ \\
		\hline
		$95$ & $26.60$ \\
		\hline
		$200$ & $53.64$ \\
		\hline
		$500$ & $144.51$ \\
		\hline
	\end{tabular}
	\caption{Gesamter Zeitbedarf der Rekonstruktion der Teilalignments für jeweils \numprint{5000} Sequenzpaare mit je \numprint{5000} Basen und einer Fehlerrate von $15$\% in Abhängigkeit des $\Delta$-Wertes}
	\label{time-table}
\end{table}

\section{Entropie beider Verfahren}
Die Entropie der CIGAR-String Repräsentation und der Trace Point Differenzen wurde für \numprint{1000} Sequenzen mit je \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $100$ und einer Fehlerrate von $15$\%, wie in Kapitel \ref{entropie-der-methoden} beschrieben, berechnet.

Die Resultate sind in Tabelle \ref{bits-result} beschrieben und in Abbildung \ref{entropy} grafisch dargestellt.

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{images/data/entropy}
	\caption{Entropie von \numprint{1000} CIGAR-Strings von DNA-Sequenzen mit je \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $100$ und einer Fehlerrate von $15$\%}
	\label{entropy}
\end{figure}

\chapter{Diskussion}

In diesem Kapitel werden die Resultate aus Kapitel \ref{Resultate} interpretiert und die Qualität der Kodierungen in Bezug auf eine speichereffiziente Repräsentation eines Alignments betrachtet.

\section{CIGAR-Kodierung}

Die Kodierungen der CIGAR-Strings, wie sie in Abbildung \ref{cigar-coding} grafisch und in Tabelle \ref{bits-result} numerisch dargestellt sind, zeigen, dass die Huffman-Kodierung mit \numprint{1458} Bit im Mittel deutlich weniger Speicher benötigt, als die unäre Kodierung mit \numprint{4290} Bit oder die binäre Kodierung mit \numprint{6595} Bit.

In CIGAR-Strings von Alignments mit einer geringen Fehlerrate ist die Anzahl der Matches deutlich höher als die der Insertions oder Deletions. Insertions und Deletions treffen dazu selten hintereinander auf, was einen Schwerpunkt der Quantität '1' zufolge hat. Für diese Art der Verteilung ist die binäre Kodierung weniger gut geeignet als die unäre oder Huffman-Kodierung, da sie keine Speicherersparnis aus häufig auftretenden Symbolen ziehen kann, sondern alle Symbole mit der selben Anzahl an Bits kodiert.

Die unäre Kodierung benötigt bei kürzeren Sequenzen, wie z.B. aus Beispiel \ref{Alignment-bsp}, weniger Speicher als die Huffman-Kodierung, da diese für die Dekodierung jedes Mal den 'Header' mitspeichern muss und sich dieser zusätzliche Speicherverbrauch bei kürzeren Sequenzen stärker auswirkt, als bei längeren. In den Resultaten wurden deutlich längere Sequenzen verwendet und es zeigt sich, dass die Huffman-Kodierung wie oben beschrieben nur etwa $34$\% des Speicherbedarfs der unären Kodierung benötigt.

Die Huffman-Kodierung ist somit für CIGAR-Strings die speichereffizienteste der drei Kodierungen.

\section{Kodierung der Differenzen der Trace Points}

Die Kodierung der Differenzen der Trace Points ist für ein $\Delta = 200$ und eine Fehlerrate von $15$\% in Abbildung \ref{tracepoint-d200} grafisch dargestellt und in der Tabelle \ref{bits-result} numerisch beschrieben. In Abbildung \ref{var-deltas} sind die Auswirkungen der Wahl des $\Delta$-Parameters auf die Größe der Kodierung und in \ref{time} auf die Rekonstruktionszeit der Teilalignments dargestellt. Die entsprechenden Werte sind in Tabelle \ref{var-errs-deltas} für die Größe der Kodierung und in Tabelle \ref{time-table} für den Zeitbedarf der Rekonstruktionszeit beschrieben. In Abbildung \ref{var-errs}, sowie Tabelle \ref{var-errs-deltas} sind die Auswirkungen der Fehlerrate der Sequenzen auf die Kodierungsgröße dargestellt.

Für einen $\Delta$-Wert von $200$ benötigt die Huffman-Kodierung im Durchschnitt nur $84.18$ Bit und damit etwa $9.3$\% weniger Speicher, als die unäre Kodierung mit $90.19$ Bit. Die binäre Kodierung liegt mit durchschnittlich $125$ Bit deutlich über dem Bedarf der anderen beiden Kodierungen. Da die einzelnen Abschnitte in der $v$-Sequenz zu $\Delta$ großen Abschnitten der $u$-Sequenz aligniert werden, sind diese üblicherweise auch genauso oder ähnlich groß wie das $\Delta$. Das hat zur Folge, dass die Differenzen der Trace Points in einem ähnlichen Wertebereich liegen und die unäre und Huffman-Kodierung aus dieser Verteilung einen Vorteil ziehen können und daher speichereffizienter kodieren, wobei der Huffman-Algorithmus etwas besser abschneidet als die unäre Kodierung.

Die Wahl des $\Delta$-Wertes kann die Größe der Kodierung deutlich beeinflussen, da dieser Wert die Anzahl der zu speichernden Symbole bestimmt. In Abbildung \ref{var-deltas} ist deutlich zu erkennen, dass die Größe der Kodierung mit einem größer werdenden $\Delta$ deutlich sinkt. Für ein $\Delta$ von $35$ werden die Trace Point Differenzen durchschnittlich mit $95$ Bit kodiert und für ein $\Delta$ von $500$ mit $76$ Bit im Mittel, also etwa $20$\% weniger. Die Regressionsgerade entspricht der Funktion $f(\Delta) = -\frac{1}{50}\Delta + 93$. Der $\Delta$-Wert kann jedoch nicht beliebig groß gewählt werden, da mit größeren Teilabschnitten der Sequenzen auch eine längere Rekonstruktionszeit der Teilalignments einher geht. Der $\Delta$-Parameter dient also als Regler für den Speicherbedarf der Kodierung.

Die Fehlerrate der Sequenzen hat ebenfalls einen großen Einfluss auf die Größe der Kodierung. Je größer die Fehlerrate, umso größer ist die Anzahl der Insertions und Deletions im Alignment und umso geringer ist die Anzahl der Matches. Da die Trace Points eine geringe Differenz zu den Vielfachen von $\Delta$ haben und somit die Differenzen der Trace Points in etwa $\Delta$ groß sind, müssen daher deutlich weniger unterschiedliche Symbole kodiert werden. In Abbildung \ref{var-errs} ist die lineare Abhängikeit der Fehlerrate in den Sequenzen von der Größe der Kodierung zu erkennen. Bei einer Fehlerrate von $35$\% wird für $\Delta = 100$ durchschnittlich $97$ Bit benötigt und für eine Fehlerrate von $5$\% im Mittel nur $44$ Bit, also etwa $55$\% weniger. Die Funktion $f(\varepsilon) = 173.45\varepsilon + 36.25$ beschreibt die Größe der Kodierung in Abhängigkeit von $\varepsilon$, welche in Abbildung \ref{var-errs} dargestellt ist.

Damit ist die Huffman-Kodierung, wie bei den CIGAR-Strings, das speichereffizienteste Kodierungs-Verfahren für die Trace Point Differenzen.

\section{Laufzeit der Rekonstruktion von Alignments}
Für die Rekonstruktion der Teilalignments wird abhängig von $\Delta$ viel Zeit benötigt, da $\Delta$ die Größe der Teilabschnitte bestimmt und die optimalen Teilalignments, wie in Kapitel \ref{methoden} beschrieben, in $O(e^2)$ Zeit mit $e$ als Edit-Distanz rekonstruiert werden können.

Die Abbildung \ref{time} verdeutlicht diese Abhängigkeit. Für $\Delta = 5$ wird demnach für die Rekonstruktion der Teilalignments von \numprint{5000} Sequenzpaaren mit je \numprint{5000} Basen etwa $4.38$ Sekunden benötigt. Für $\Delta = 500$ werden hingegen etwa $144.51$ Sekunden benötigt, also etwa $33$ mal so viel wie für $\Delta = 5$. Der Zeitbedarf in Sekunden lässt sich durch die Funktion $f(\Delta) = 0.28\Delta - 1.23$ beschreiben.

Mit Hilfe von $\Delta$ kann somit die Zeit, die für die Rekonstruktion der Teilalignments benötigt wird, eingestellt werden.

\section{Entropie beider Methoden}

Die Größe der Entropie der CIGAR-Strings und Trace Point Differenzen ist für \numprint{1000} Sequenzenpaare mit je \numprint{5000} Basen, einem $\Delta$-Wert von $100$ und einer Fehlerrate von $15$\% in Abbildung \ref{entropy} grafisch dargestellt und in der Tabelle \ref{bits-result} numerisch beschrieben.

Sie gibt den Informationsgehalt einer Sequenz abhängig von der Häufigkeitsverteilung der Symbole an und wird deshalb in Bit pro Symbol berechnet und dann später mit der Anzahl der zu kodierenden Symbole multipliziert. Da ein CIGAR-String alle Edit-Operationen eines Alignments beschreibt und die Trace Point Differenzen lediglich die Abstände von einem zu alignierenden Abschnitt zu dem nächsten beschreiben, müssen in der Regel für CIGAR-Strings mehr Symbole kodiert werden, als für die Trace Point Differenzen. Diese Eigenschaft spiegelt sich auch in der Entropie beider Verfahren wieder. Die CIGAR-Strings weisen eine Entropie von durchschnittlich \numprint{1755} Bit auf. Dies bedeutet, dass sie etwa $13$ mal so viel wie die Entropie der Trace Point Differenzen ausmacht, welche bei durchschnittlich $134$ Bit liegt.
	
\chapter{Fazit}

Das Verfahren der Trace Point Differenzen stellt im Vergleich zu der üblichen Repräsentation von Alignments als CIGAR-String eine deutlich speichereffizientere Methode dar. Insbesondere durch eine Huffman-Kodierung der Differenzwerte kann bei den in dieser Arbeit errechneten Größen eine Speicherersparnis von etwa $77$\% gegenüber den CIGAR-Strings erzielt werden. Hierbei spielt jedoch der vorher definierte positive Parameter $\Delta$ eine entscheidende Rolle.

Je größer $\Delta$ gewählt ist, umso weniger Trace Points werden gespeichert und umso länger dauert die Berechnung, um die Teil-Alignments zu rekonstruieren. Bei einem kleinen $\Delta$ werden analog mehr Trace Points gespeichert, aber die Rekonstruktionszeit der Teil-Alignments ist entsprechend geringer.

Mithilfe von $\Delta$ lässt sich somit ein Trade-Off zwischen dem Speicherplatzverbrauch und dem Zeitbedarf für die Rekonstruktion der Teil-Alignments einstellen.
