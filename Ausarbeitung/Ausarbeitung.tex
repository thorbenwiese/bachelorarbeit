\chapter{Einleitung}

Ein Sequenzalignment wird in der Bioinformatik dazu verwendet, zwei oder mehrere Sequenzen von zum Beispiel DNA-Strängen oder Proteinsequenzen miteinander zu vergleichen und die Verwandtschaft zu bestimmen. Ein Alignment ist das Ergebnis eines solchen Vergleichs. Bei einem globalen Alignment wird jeweils die gesamte Sequenz betrachtet, bei einem lokalen Alignment lediglich Teilabschnitte der beiden Sequenzen.
Um die verschiedenen Sequenzen vergleichen zu können, berechnet man einen Score oder die Kosten, um den Aufwand, den man betreiben muss, um die gegebenene Sequenz in die Zielsequenz umzuwandeln, beschreiben zu können. Hierbei wird jeweils das Optimum, also entweder der maximale Score oder die minimalen Kosten gesucht.
Die verschiedenen Schritte, um die Symbole der Strings zu verändern, sind bei Gleichheit ein 'match', bei der Substitution ein 'mismatch', bei der Löschung eine 'deletion' und bei der Einfügung eine 'insertion', welche je nach Verfahren unterschiedlich gewichtet werden können. Hierbei haben ähnliche Sequenzen einen hohen Score und geringe Kosten und unterschiedliche Sequenzen analog einen kleinen Score und hohe Kosten.

Ziel dieser Bachelorarbeit ist es, verschiedene Repräsentationen von paarweisen Sequenzalignments und deren Kodierungen zu beschreiben und zu vergleichen, sowie basierend auf einer eigenen Implementierung einer speichereffizienten Repräsentation Unterschiede zu diskutieren.

\section*{Die Edit-Operationen}

Die in diesem Kapitel eingeführten Begriffe werden in \cite[S. 5-7, 14-16]{gsa-skript} definiert.

Sei $\mathcal{A}$ eine endliche Menge von Buchstaben, die man Alphabet nennt. Für DNA-Sequenzen verwendet man üblicherweise die Menge der Basen, also $\mathcal{A} = \{a, c, g, t\}$. $\mathcal{A}^i$ sei die Menge der Sequenzen der Länge $i$ aus $\mathcal{A}$ und $\varepsilon$ sei die leere Sequenz. Formal ausgedrückt ist eine Edit-Operation ein Tupel 
\[(\alpha, \beta) \in (\mathcal{A}^1 \cup \{\varepsilon\}) \times (\mathcal{A}^1 \cup \{\varepsilon\}) \backslash \{(\varepsilon, \varepsilon)\}.\]

Eine äquivalente Schreibweise von $(\alpha,\beta)$ ist $\alpha \rightarrow \beta$. Es gibt drei verschiedene Edit-Operationen
\begin{align*}
a \rightarrow \varepsilon &\indent \text{ ist eine Deletion für alle }a \in \mathcal{A}\\
\varepsilon \rightarrow b &\indent \text{ ist eine Insertion für alle }b \in \mathcal{A}\\
a \rightarrow b &\indent \text{ ist eine Substitution für alle }a,b \in \mathcal{A}
\end{align*}
Dabei ist zu beachten, dass $\varepsilon \rightarrow \varepsilon$ keine Edit-Operation darstellt.

Ein Alignment von zwei Sequenzen $u$ und $v$ lässt sich nun als eine Sequenz $(\alpha_1 \rightarrow \beta_1, ... , \alpha_h \rightarrow \beta_h)$ von Edit-Operationen definieren, sodass $u = \alpha_1 ... \alpha_h$ und $v = \beta_1 ... \beta_h$ gilt.

Üblicherweise wird ein Alignment in drei Zeilen wie folgt geschrieben. In der ersten Zeile schreibt man die Sequenz $u$ und in der dritten Zeile die Sequenz $v$. In der mittleren Zeile symbolisiert das Zeichen '$|$' einen Match. Außerdem wird ein $\varepsilon$ aus der Edit-Operation durch das Zeichen '$-$' dargestellt.

\begin{bsp}
	Sei von $u$ und $v$ das folgende Alignment $A = (a\rightarrow a, c\rightarrow c, t\rightarrow t, \varepsilon \rightarrow a, g \rightarrow g, a \rightarrow a, a \rightarrow a, c \rightarrow \varepsilon, t \rightarrow t)$ gegeben. 
	\begin{center}
		\texttt{
			\begin{tabular}{ccccccccc}
				a & c & t & - & g & a & a & c & t\\
				$|$&$|$&$|$&&$|$&$|$&$|$& &$|$\\
				a&c&t&a&g&a&a& - &t
			\end{tabular}
		}
	\end{center}
	\label{Bsp1}
\end{bsp}

\section*{Die Edit-Distanz}

Sei eine Kostenfunktion $\delta$ mit $\delta(a\rightarrow b)\geq 0$ für alle Substitutionen $a \rightarrow b$ und $\delta(\alpha \rightarrow \beta)>0$ für alle Einfügungen und Löschungen $\alpha \rightarrow \beta$ gegeben. Die Kosten für ein Alignment $A = (\alpha_1 \rightarrow \beta_1, ... , \alpha_h \rightarrow \beta_h)$ ist die Summe der Kosten aller Edit-Operationen des Alignments.
\[\delta(A) = \sum_{i=1}^{h}\delta(\alpha_i \rightarrow \beta_i)\]
Ein Beispiel einer Kostenfunktion ist die Einheitskostenfunktion
\[
\delta(\alpha \rightarrow \beta) = 
\begin{cases} 
0 ,& \text{wenn } \alpha,\beta \in \mathcal{A} \text{ und } \alpha=\beta \\
1 , & \text{sonst.}
\end{cases}
\]
Die Edit-Distanz von zwei Sequenzen ist wie folgt definiert:
\[edist_\delta(u,v) = \min\{\delta(A) \mid A \text{ ist Alignment von }u \text{ und }v\}\]
Ein Alignment A ist optimal, wenn $\delta(A) = edist_\delta(u,v)$ gilt.\\[0,5cm]
Wenn $\delta$ die Einheitskostenfunktion ist, so ist $edist_\delta(u,v)$ die Levenshtein Distanz \cite[S. 19-21]{gsa-skript}.

Ein Alignment kann für eine Edit-Distanz $e$ mit der Einheitskostenfunktion in $O(e)$ Zeit berechnet werden \cite[S. 41-42]{gsa-skript}.

\chapter{Kodierung}

Das effiziente Speichern der Alignments wird durch die Kodierung der Daten maßgebend beeinflusst. Drei der gängigsten Kodierungsverfahren, welche in diesem Kapitel beschrieben werden, sind die naive binäre Kodierung, die unäre Kodierung und die Huffman-Kodierung. 

\section{Naive Binäre Kodierung}

Bei einer naiven binären Kodierung wird jedes Symbol $a$ aus dem Alphabet der zu kodierenden Symbole $\cal{A}$ mit $\lceil \log_2$$|\cal{A}|$$\rceil$ Bit kodiert, was den Vorteil hat, dass alle Codewörter die gleiche Länge haben.

\section{Unäre Kodierung}

Die unäre Kodierung kodiert jedes Symbol nach der Häufigkeit des Auftretens im Alphabet mit $i - 1$ $'0'$-Bits, gefolgt von einem $'1'$-Bit, wobei $i$ die Position des Symbols in einer nach der Häufigkeit absteigend sortierten Liste ist. Das am Häufigsten auftretende Symbol des Alphabets wird also mit $'1'$, das zweithäufigste mit $'01'$, das dritthäufigste mit $'001'$ usw. kodiert \cite[S. 29-30]{coding}. Diese Art der Kodierung bietet sich insbesondere dann an, wenn ein zu kodierendes Symbol deutlich häufiger auftritt, als die anderen Symbole. Außerdem hat jedes Codewort die Größe $1$, was den Vorteil hat, dass lediglich die Länge variiert.

\section{Huffman-Kodierung}

Bei einer \textit{minimalen} binären Kodierung, wie sie auch im Huffman-Alogrithmus verwendet wird, werden die Längen der Codewörter anhand der Häufigkeiten der Symbole in der zu kodierenden Sequenz angepasst. Hierbei werden häufig vorkommende Symbole kurzen Codewörtern zugeordnet und weniger häufige Symbole längeren Codewörtern. Somit lässt sich eine Kodierung ermöglichen, welche im Durchschnitt weniger Bit pro Symbol beansprucht. Jedes Codewort ist dabei nie der Anfang eines anderen Codewortes, was den Code präfixfrei macht und die Codewörter somit eindeutig zugeordnet werden können \cite[S. 53-57]{coding}. 

Als Datenstruktur wird hierbei eine priorisierte Queue verwendet, welche nach den Häufigkeiten der Symbole sortiert ist. Der Algorithmus wählt immer die zwei Symbole mit den geringsten Häufigkeiten aus und fügt sie als ein Symbol zusammen, bis am Ende alle Symbole zusammengefügt wurden. So wird rekursiv ein Baum aufgebaut, welcher am Ende durch das Hinzufügen von den Kantengewichten $0$ und $1$ die Kodierungen der einzelnen Symbole bestimmt. Der Pseudocode des Algorithmus ist in Algorithmus $1$ dargestellt \cite{fastq-compress}.

Immer wenn die Wahl zwischen mehreren Symbolen mit der selben Häufigkeit getroffen werden muss, kann eine Regel eingeführt werden. Beispielsweise können immer die zwei Symbole, die im Alphabet oder numerisch vor den anderen stehen, ausgewählt werden. Hierdurch wird die  Kodierungen eindeutig. Diese Art der Kodierung nennt man eine 'kanonischen' Kodierung.

Der 'kanonische' Huffman-Algorithmus benötigt aufgrund der oben genannten Eigenschaften lediglich die Anzahl der Codewörter für jede vorhandene Codewortlänge, sowie die sortierten Symbole benötigt, um die Informationen zu dekodieren \cite{canonical}.

\begin{algorithm}
	\caption{Pseudocode des Huffman-Algorithmus}
	\noindent\begin{tabular}{@{}l@{~}l}
		\textbf{Parameter}:
		& $\cal{A}$ ist das Alphabet der zu kodierenden Symbole mit den Häufigkeiten \\
		& $p(a)$ für alle $a \in \ $$\cal{A}$.
	\end{tabular}
	\medskip
	\begin{algorithmic}[1]
		\Function{\textit{Huffman}}{$\cal{A}$$ , p(a)$}
		\State assert(\Size{$\cal{A}$}$ > 0$)
		\State assert($p(a) > 0$)
		\State \Assign{Q}{\emptyset \textit{ als leere priorisierte Queue}}
		\For{\textbf{all} $a \in $$\cal{A}$}
		\State erzeuge neuen Knoten $z$
		\State $(z.\textit{links}, z.\textit{rechts}, z.\textit{char}, z.\textit{count}) = ($nil, nil, $a, p(a))$
		\State füge $z$ in $Q$ ein
		\EndFor
		\While{$\Size{Q} \geq 2$}
		\State \Assign{x}{extractmin(Q)}
		\State \Assign{y}{extractmin(Q)}
		\State erzeuge neuen Knoten $z$
		\State \Assign{(z.\textit{links}, z.\textit{rechts}}{(y, x)}
		\State \Assign{z.\textit{char}}{x.\textit{char} < y.\textit{char} \text{ ? } y.\textit{char} \text{ : } x.\textit{char}}
		\State \Assign{z.\textit{count}}{x.\textit{count} + y.\textit{count}}
		\State füge $z$ in $Q$ ein
		\EndWhile
		\State \Assign{root}{z}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\chapter{Methoden}

\section{CIGAR-Strings}

Ein Dateiformat, welches zur Speicherung von Alignments verwendet wird, ist das SAM-Format oder die binär komprimierte Version BAM. Dieses codiert ein Alignment in einem sogenannten CIGAR-String, der aus einzelnen Zeichen besteht, die jeweils eine Edit-Operation bezeichnen, also M für eine Substitution, I für eine Insertion und D für eine Deletion. Gleiche aufeinanderfolgende Operationen werden als Kombination von Quantität und Symbol geschrieben.

\begin{defi}
Eine Folge von abwechselnd Quantitäten und Edit-Operationen $C = s_1c_1s_2c_2...s_nc_n$ ist ein CIGAR-String mit der Länge $|C| = 2n$ eines Alignments für alle Symbole $s \in \{$M$,$I$,$D$\}$ und alle Quantitäten $c \in \mathbb{N}$.
\end{defi}

\begin{bsp}
Sei folgendes Alignment aus Beispiel \ref{Bsp1} gegeben.
\begin{center}
	\texttt{
		\begin{tabular}{ccccccccc}
			a & c & t & - & g & a & a & c & t\\
			$|$&$|$&$|$&&$|$&$|$&$|$& &$|$\\
			a&c&t&a&g&a&a& - &t
		\end{tabular}
	}
\end{center}
Dieses Alignment wird duch den CIGAR-String \texttt{3M1I3M1D1M} repräsentiert \cite{sam}.
\end{bsp}

\subsection{Kodierung eines CIGAR-Strings}\label{Cigar_Speicher}

Für die Kodierung eines CIGAR-Strings ist es sinnvoll, alle Quantitäten und Symbole seperat zu kodieren, um so mit kleineren Alphabeten für die zu kodierenden Symbole arbeiten zu können.

$\cal{A}$$_s = \{$M$, $I$, $D$\}$ und $\cal{A}$$_c = \{s_i \mid 1 \leq i \leq n\}$ sind somit die Alphabete der zu kodierenden Symbole eines CIGAR-Strings.

Im Folgenden vergleiche ich ausführlich für den CIGAR-String eines Alignments die Verfahren der naiven binären Kodierung, der unären Kodierung und der Huffman-Kodierung.

\FloatBarrier

\begin{bsp}
Sei das Alignment $A$

\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0   
\end{verbatim}
gegeben, welches durch den CIGAR-String \texttt{4M1I1M1I1M1I1M2D1M1D1M1I8M\\1D7M1D5M1I4M} repräsentiert werden kann.

Sei außerdem das Alphabet $\cal{A}$$_s$ $= \{$M$, $I$, $D$\}$, welches alle Symbole aus dem CIGAR-String enthält, das Alphabet $\cal{A}$$_c$ $= \{1, 2, 4, 5, 7, 8\}$, welches alle Zahlen aus dem CIGAR-String enthält, sowie die Häufigkeiten jeden Symbols gegeben.

Bei einer naiven binären Kodierung wird jedes Symbol $a \in \cal{A}$$_{s,c}$ mit $\lceil \log_23\rceil + \lceil \log_26\rceil = 2 + 3 = 5$ Bit pro Symbol kodiert. Insgesamt ergibt das somit $19 \cdot 5 = 95$ Bit.

Die unäre Kodierung des oben genannte CIGAR-Strings ist in Tabelle \ref{cigar-unary} beschrieben. Sie benötigt folglich $32 + 35 = 67$ Bit.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
		\hline
		M & $10$ & $1$ & $10 \cdot 1 = 10$\\
		D & $5$ & $01$ & $5 \cdot 2 = 10$\\
		I & $4$ & $001$ & $4 \cdot 3 = 12$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$32$\\
		&&
	\end{tabular}
	
	\begin{tabular}{cccr}
	Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
	\hline
	$1$ & $13$ &$1$ & $13 \cdot 1 = 13$\\
	$4$ & $2$ &$01$ & $2 \cdot 2 = \ \ 4$\\
	$2$ & $1$ &$001$ & $1 \cdot 3 =\ \ 3$\\
	$5$ & $1$ &$0001$ & $1 \cdot 4 =\ \ 4$\\
	$7$ & $1$ &$00001$ & $1 \cdot 5 =\ \ 5$\\
	$8$ & $1$ &$000001$ & $1 \cdot 6 =\ \ 6$\\
	\hline
	\multicolumn{3}{l}{Gesamtanzahl:}&$35$
\end{tabular}
\caption{Unäre Kodierung des CIGAR-Strings}
\label{cigar-unary}
\end{table}

Der kanonische Huffman-Algorithmus würde bei dem oben genannten Beispiel des CIGAR-Strings nach \cite[S. 54]{coding} die Symbole wie in Tabelle \ref{cig-huf-coding} beschrieben kodieren. Die Huffman-Bäume beider Alphabete sind in Abbildung \ref{Huff-Tree-Cig} dargestellt. Für die Dekodierung sind somit zusätzlich die Listen $(1,2),($M$, $D$, $I$)$ und $(1,1,0,4),(1,4,2,5,7,8)$ zu speichern. Diese können als sogenannter 'Header' am Anfang der kodierten Datei unär kodiert werden. In diesem Fall würde der Header als $01001;0001$ und $0101100001;0000001$ kodiert werden, wobei jeweils der erste Teil die Häufigkeiten der Code-Längen und der zweite Teil die Gesamtanzahl der Symbole kodiert.

Die Größe dieser Kodierung ist demnach $28 + 33 + 9 + 17 = 87$ Bit.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung & Anzahl Bits\\
		\hline
		M & $10$ &$0$ & $10 \cdot 1 = 10$\\
		D & $5$ &$10$ & $5 \cdot 2 = 10$\\
		I & $4$ &$11$ & $4 \cdot 2 =\ \ 8$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$28$\\
		&&&
	\end{tabular}
	
	\begin{tabular}{cccr}
	Symbol & Häufigkeit & Kodierung & Anzahl Bits\\
	\hline
	$1$ & $13$ & $0$ & $13 \cdot 1 = 13$\\
	$4$ & $2$ & $10$ & $2 \cdot 2 =\ \ 4$\\
	$2$ & $1$ & $1100$ & $1 \cdot 4 =\ \ 4$\\
	$5$ & $1$ & $1101$ & $1 \cdot 4 =\ \ 4$\\
	$7$ & $1$ & $1110$ & $1 \cdot 4 =\ \ 4$\\
	$8$ & $1$ & $1111$ & $1 \cdot 4 =\ \ 4$\\
	\hline
	\multicolumn{3}{l}{Gesamtanzahl:}&$33$
\end{tabular}
\caption{Huffmann-Kodierung des CIGAR-Strings}
\label{cig-huf-coding}
\end{table}

\begin{figure}[t]
	\centering
	\begin{forest}
		for tree={grow'=south}
		[$\frac{19}{38}$
		[$\frac{9}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[I, edge label={node[midway,right,font=\scriptsize]{1}}]
		[D, edge label={node[midway,left,font=\scriptsize]{0}}] ] 
		[M, edge label={node[midway,left,font=\scriptsize]{0}}] ]
		]
	\end{forest}
	\begin{tabular}{ccc}
		&&
	\end{tabular}
	\begin{forest}
		for tree={grow'=south}
		[$\frac{19}{38}$
		[$\frac{6}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$\frac{4}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$\frac{2}{38}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$8$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$7$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$\frac{2}{38}$, edge label={node[midway,left,font=\scriptsize]{0}}
		[$5$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$2$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]]
		[$4$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$1$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]
	\end{forest}
	\caption{Huffman-Bäume der Kodierung des CIGAR-Strings}
	\label{Huff-Tree-Cig}
\end{figure}
\label{Alignment-bsp}
\end{bsp}

\section{Trace Point Konzept}

Ein neuer Ansatz der speichereffizienten Repräsentation von Alignments wurde von Gene Myers in \cite{myers} beschrieben und basiert auf dem Konzept der Trace Points.

Der Grundgedanke dieser Methode ist es, das Alignment zweier gegebener Sequenzen nicht als solches kodiert abzuspeichern, sondern stattdessen die erste Sequenz in gleich große Abschnitte zu unterteilen und die Endpunkte, sogenannte Trace Points, von Teilabschnitten des Alignments in der zweiten Sequenz abzuspeichern. So kann für jeden Teilabschnitt jeweils ein Teilalignment berechnet werden. Für die Unterteilung der ersten Sequenz wird der positive Parameter $\Delta$ verwendet. Die Teilalignments können dann zu einem Gesamtalignment konkateniert werden.

Das Verfahren bietet den Vorteil, durch die Größe der Teilabschnitte die Anzahl der Trace Points und somit den Speicherbedarf, sowie die Zeit, die für die Berechnung der Teilalignments benötigt wird, anpassen zu können.

Sei $A$ ein Alignment von $u[i...j]$ und $v[k...\ell]$ mit $i < j$ und $k < l$ und sei $\Delta \in \mathbb{N}$. Sei außerdem für die dynamische Anpassung der Intervallgrenzen der Parameter $p$ gegeben mit
\[ p = \begin{cases}
\left \lceil\frac{i}{\Delta}\right \rceil & \text{falls } i > 0\\
1 & \text{falls }i = 0.
\end{cases}\]

Man unterteilt $u[i...j]$ in $\tau = \left \lceil\frac{j}{\Delta}\right \rceil - \left \lfloor\frac{i}{\Delta}\right \rfloor$ Substrings $u_0, u_1, ... , u_{\tau -1}$ mit
\[  
u_q =
\begin{cases} 
u[i...p\cdot\Delta] & \text{falls }q = 0 \\
u[(p+q-1)\cdot\Delta+1...(p+q)\cdot\Delta] & \text{falls }0<q<\tau -1\\
u[(p+\tau-2)\cdot\Delta...j] & \text{falls }q = \tau -1
\end{cases}
\]

Für alle $q$ mit $ 0 \leq q < \tau -1$ sei $t_q$ der letzte Index des Substrings von $v$, der in A mit $u_q$ aligniert. $t_q$ nennt man Trace Point. Für $q = 0$ aligniert $u_0$ mit $v_0 = v[k...t_0]$. Für alle $q$ mit $0<q< \tau -1$ aligniert $u_q$ mit $v_q = v[t_{q-1}+1...t_q]$.

Seien $i,j,k,\ell,\Delta$ und die Trace-Points eines Alignments von $u$ und $v$ gegeben. Dann kann ein Alignment $A'$ von $u$ und $v$ mit $\delta (A') \leq \delta (A)$ konstruiert werden. Danach bestimmt man aus den Trace-Points die Substring-Paare $u_q$ und $v_q$, berechnet hierfür jeweils ein optimales Alignment und konkateniert die Alignments von den aufeinanderfolgenden Substring-Paaren zu $A'$.

%TODO Seitenumbruch beachten
\begin{bsp}

Sei $\Delta = 15$ und folgendes Alignment gegeben:

\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0    
\end{verbatim}

Beide Sequenzen seien in dem Intervall von $0$ bis $37$. Das Alignment wird wie oben beschrieben in $\tau = \left \lceil\frac{37}{15}\right \rceil - \left \lfloor\frac{0}{15}\right \rfloor = 3 - 0 = 3$ Abschnitte unterteilt. Der erste Abschnitt ist in $u$ von $0$ bis $14$ und in $v$ von $0$ bis $15$.
\begin{verbatim}
gagc-a-t-gttgcc-tgg
|| | | | |  | | |||
gaccaagtag--g-cgtgg
\end{verbatim}
Der zweite Abschnitt ist in $u$ von $15$ bis $29$ und in $v$ von $16$ bis $28$.
\begin{verbatim}
tcctttgctaggtac
|||| ||| ||| |
acctt-gctcggt-c
\end{verbatim}
Der dritte Abschnitt ist in $u$ von $30$ bis $37$ und in $v$ von $29$ bis $37$.
\begin{verbatim}
tgta-gaga
|||| ||||
tgtaagaga
\end{verbatim}
Somit ergeben sich als Endpunkte aller Abschnitte außer dem letzten Abschnitt die Trace Points $15$ und $28$.
\end{bsp}

\subsection{Differenzen-Kodierung}\label{Differenzen-Kodierung}

Gegeben sei eine Liste $L = (a_1, a_2, ... , a_n)$ mit $a_i < a_{i+1}, 0 < i < n$.

Anstatt jeden Wert $a \in L$ als solchen abzuspeichern, kann alternativ die Differenz eines Wertes $a_i$ zu dem nachfolgenden Wert $a_{i+1}$ abgespeichert werden. Lediglich der erste (oder letzte) Wert aus $L$ wird benötigt, um später sukzessive die ursprüngliche Liste rekonstruieren zu können.
\[L_{\mathit{diff}} = (a_1, (a_2-a_1), (a_3-a_2), ... , (a_{n}-a_{n-1}))\]

Bei gleichmäßig ansteigenden Werten ist die Abweichung der Differenzen zweier aufeinanderfolgender Werte in der Liste untereinander gering und die Menge der zu kodierenden Symbole verringert sich.

Im Folgenden Beispiel werde ich die Kodierung der Trace Point Differenzen ausführlich für die naive binäre, unäre und Huffman-Kodierung erläutern.

\begin{bsp}
Sei $\Delta = 5$ und das Alignment $A$
\begin{verbatim}
0    5    0    5    0    5    0    5    0    
gagc-a-t-gttgcc-tggtcctttgctaggtactgta-gaga
|| | | | |  | | ||| |||| ||| ||| ||||| ||||
gaccaagtag--g-cgtggacctt-gctcggt-ctgtaagaga
0    5    0    5    0    5    0    5    0   
\end{verbatim}

wie in Abschnitt \ref{Cigar_Speicher} mit den dazugehörigen TracePoints $5, 10, 15, 20, 24, 28$ und $34$ gegeben. Es ergibt sich somit das Alphabet $\cal{A}$ $= \{5, 10, 15, 20, 24, 28, 34\}$ mit ausschließlich positiven und aufsteigenden Werten.

Für die Trace Point Darstellung ist in diesem Beispiel somit eine Differenzen-Kodierung möglich.

Als neue Liste zu kodierender Werte ergibt sich nach \ref{Differenzen-Kodierung} $L_{\mathit{diff}} = (5, 5, 5, 5, 4, 4, 6)$.

Um aus den Trace Points ein neues Alignment rekonstruieren zu können, benötigt man zusätzlich mindestens den $\Delta$-Wert, damit die Grenzen der Substrings beider Sequenzen berechnet werden können. Hierfür muss also der $\Delta$-Wert zu $L_{\mathit{diff}}$ hinzugefügt werden.

Für das oben genannten Beispiel ergibt sich somit
\begin{center}
\begin{tabular}{rcl}
	$L_{\mathit{diff}}$ &$=$& $(\Delta, a_1, (a_2-a_1), (a_3-a_2), ... , (a_{n}-a_{n-1}))$\\
	&$=$ & $(5, 5, 5, 5, 5, 4, 4, 6)$
\end{tabular}
\end{center}

sowie das Alphabet $\cal{A}$ $= \{4, 5, 6\}$. 

Bei der naiven binären Kodierung von $L_{\mathit{diff}}$ ergibt sich analog zu \ref{Cigar_Speicher} ein Bedarf von $\lceil \log_28\rceil = 3$ Bit pro Symbol, also $8 \cdot 3 = 24$ Bit insgesamt und damit nur  $\frac{24}{95} = 25.26$\% der binären Kodierung für den CIGAR-String.

Die unäre Kodierung ergibt für dieses Beispiel die in Tabelle \ref{diff-unary} beschriebene Kodierung. Die Größe dieser Kodierung ist demnach $12$ Bit und benötigt damit nur $\frac{12}{67} = 17.91$\% der unären Kodierung für den CIGAR-String.

\begin{table}[t]
	\centering
	\begin{tabular}{cccr}
		Symbol & Häufigkeit & Kodierung &  Anzahl Bits\\
		\hline
		$5$ & $5$ &$0$ & $5 \cdot 1 = 5$\\
		$4$ & $2$ &$10$ & $2 \cdot 2 = 4$\\
		$6$ & $1$ &$110$ & $1 \cdot 3 = 3$\\
		\hline
		\multicolumn{3}{l}{Gesamtanzahl:}&$12$
	\end{tabular}
	\caption{Unäre Kodierung der Differenzen-Kodierung}
	\label{diff-unary}
\end{table}

Die Ausführung des Huffman-Algorithmus kodiert nach \cite[S. 54]{coding} die Symbole wie in Tabelle \ref{Diff-Huff} aufgelistet. Der dazugehörige Huffmann-Baum aus \ref{Huff-Tree-Diff} verdeutlicht die Kodierung der einzelnen Symbole, muss aber für den kanonischen Huffman-Algorithmus, wie in \ref{Cigar_Speicher} beschrieben, nicht komplett gespeichert werden. Aufgrund der Beschaffenheit der Codewörter des kanonischen Huffman-Algorithmus ist hier lediglich die Speicherung der Listen $(1,2),(5,4,6)$, welche als $01001;0001$ im Header kodiert werden, nötig.

Die Größe der kanonischen Huffman-Kodierung ist demnach $11 + 9 = 20$ Bit und benötigt damit nur $\frac{20}{70} \approx 28$\% der Huffman-Kodierung für den CIGAR-String.

\begin{table}
	\centering
	\begin{tabular}{ccr}
		Symbol & Kodierung & Anzahl Bits\\
		\hline
		$5$ & $0$ & $5 \cdot 1 = 5$\\
		$4$ & $10$ & $2 \cdot 2 = 4$\\
		$6$ & $11$ & $1 \cdot 2 = 2$\\
		\hline
		\multicolumn{2}{l}{Gesamtanzahl:}&$11$
	\end{tabular}
	\caption{Huffman-Kodierung der Differenzen-Kodierung}
	\label{Diff-Huff}
\end{table}

\begin{figure}
	\centering
	\begin{forest}
		for tree={grow'=south}
		[$\frac{8}{8}$
		[$\frac{3}{8}$, edge label={node[midway,right,font=\scriptsize]{1}}
		[$6$, edge label={node[midway,right,font=\scriptsize]{1}}]
		[$4$, edge label={node[midway,left,font=\scriptsize]{0}}]]
		[$5$, edge label={node[midway,left,font=\scriptsize]{0}}]
		]
	\end{forest}
	\caption{Huffman-Baum der Differenzen-Kodierung}
	\label{Huff-Tree-Diff}
\end{figure}
\end{bsp}

\section{Entropie der Methoden}

Die Entropie $H$ beschreibt den durchschnittlichen Informationsgehalt einer Sequenz $S$ für alle Symbole $a \in S$ mit den relativen Wahrscheinlichkeiten $p(a)$ jeden Symbols in der Einheit $\frac{\text{Bit}}{\text{Symbol}}$.
\[H(S) = - \sum_{a \in S}p(a) \cdot \log_2p(a)\]
Sie ist maximal, wenn alle Symbole mit der gleichen Wahrscheinlichkeit $\frac{1}{|S|}$ auftreten \cite{entropy}.

Für den in \ref{Cigar_Speicher} genannten CIGAR-String ergibt sich eine Entropie von

\begin{center}
\begin{tabular}{rcl}
	$H(\mathit{Cigar})$ &$=$& $-(\frac{10}{38} \cdot \log_2\frac{10}{38} + \frac{5}{38} \cdot \log_2\frac{5}{38} + \frac{4}{38} \cdot \log_2\frac{4}{38} + \frac{13}{38} \cdot \log_2\frac{13}{38} + \frac{2}{38} \cdot$\\
	&&$\log_2\frac{2}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38} + \frac{1}{38} \cdot \log_2\frac{1}{38})$\\
	&$\approx$& $2.54\ \frac{\text{Bit}}{\text{Symbol}}$
\end{tabular}
\end{center}

und somit eine Gesamtentropie von $2.54 \cdot 38 = 96.52$ Bit.

Die in \ref{Differenzen-Kodierung} genannten Trace Point Differenzen des selben Alignments ergeben analog

\begin{center}
\begin{tabular}{rcl}
	$H(\mathit{Diff})$ &$=$& $-(\frac{5}{8} \cdot \log_2\frac{5}{8} + \frac{2}{8} \cdot \log_2\frac{2}{8} + \frac{1}{8} \cdot \log_2\frac{1}{8})$\\
	&$\approx$& $1.30\ \frac{\text{Bit}}{\text{Symbol}}$
\end{tabular}
\end{center}

und somit eine Gesamtentropie von $1.30 \cdot 8 = 10.4$ Bit.

Zusammenfassend ergibt sich für das Alignment aus Beispiel \ref{Bsp1} die folgende Tabelle:
\begin{figure}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		&CIGAR-String&Trace Point Differenzen\\
		\hline
		Binäre Kodierung&$95$&$24$\\
		\hline
		Unäre Kodierung&$67$&$12$\\
		\hline
		Huffman-Kodierung&$87$&$21$\\
		\hline
		Entropie&$96.52$&$10.4$\\
		\hline
	\end{tabular}
	\caption{Anzahl der Bits für die Kodierung des Beispiel-Alignments}
\end{figure}

\chapter{Resultate} \label{Resultate}

Um von den Kodierungen des Alignments aus Beispiel \ref{Alignment-bsp} auf die Verteilung einer großen Anzahl von Alignments schließen zu können, habe ich die verschiedenen Kodierungen für jeweils CIGAR-Strings und Trace Point Differenzen mit unterschiedlichen Parametern, sowie die Verteilung der Entropie der zwei Verfahren berechnet und grafisch dargestellt.

Die Resultate dieser Berechnungen werden in diesem Kapitel detailliert beschrieben.

\section{CIGAR Kodierung}\label{Cigar_Testläufe}

Für die Kodierung der CIGAR-Strings wird zunächst eine zufällig angeordnete DNA-Sequenz und daraus mit der jeweiligen Fehlerrate eine abgewandelte Sequenz berechnet. Dieser Vorgang wiederholt sich mehrfach. Aus einem Sequenzpaar wird dann ein Alignment berechnet, aus dem der CIGAR-String extrahiert wird. Dieser wird dann mit den oben beschriebenen Verfahren kodiert und die Anzahl der Bits, die für die jeweilige Kodierung benötigt werden, werden berechnet und deren Verteilung in Abbildung \ref{cigar-coding} grafisch dargestellt. Die gemessenen Werte sind in Tabelle \ref{cigar-result} verdeutlicht.

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{coding/new/cigar-1000-5000-d100}
	\caption{Häufigkeitsverteilung der Kodierungen für \numprint{1000} CIGAR-Strings von DNA Sequenzen mit je \numprint{5000} Basenpaaren und einer Fehlerrate von $15$\%.} \label{cigar-coding}
\end{figure}

\begin{figure}[t]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		&Minimum&Maximum&$\diameter$\\
		\hline
		Binäre Kodierung&\numprint{4480}&\numprint{9100}&\numprint{6595.50}\\
		\hline
		Unäre Kodierung&\numprint{3500}&\numprint{5100}&\numprint{4290.94}\\
		\hline
		Huffman-Kodierung&\numprint{1300}&\numprint{1625}&\numprint{1458.02}\\
		\hline
	\end{tabular}
	\caption{Anzahl der Bits für die Kodierungen der CIGAR-Strings}
	\label{cigar-result}
\end{figure}

\FloatBarrier

Die naive binäre Kodierung der CIGAR-Strings benötigt, wie in Abbildung \ref{cigar-result} dargestellt, für \numprint{1000} Sequenzpaare mit je \numprint{5000} Basen im Mittel \numprint{6595.50} Bit, wobei Werte zwischen \numprint{4480} und \numprint{9100} Bit erreicht werden. Diese bilden ein Maximum bei $120$ Sequenzpaaren mit jeweils etwa \numprint{6500} Bit.

Für die unäre Kodierung der selben CIGAR-Strings werden Werte zwischen \numprint{3500} und \numprint{5100} Bit erreicht, wobei der Durchschnitt bei \numprint{4290.94} und damit etwa $35$\% unter dem der naiven binären Kodierung liegt. Das Maximum liegt hier bei $155$ Sequenzpaaren, deren CIGAR-Strings mit je etwa $4200$ Bit kodiert werden.

Die Huffman-Kodierung kodiert die CIGAR-Strings zwischen \numprint{1300} und \numprint{1625} Bit, wobei das Maximum von $180$ Sequenzpaaren mit \numprint{1500} Bit erreicht wird. Der Mittelwert liegt hier bei \numprint{1458.02} Bit und damit etwa $78$\% unter dem der naiven binären Kodierung und etwa $66$\% unter dem der unären Kodierung.

\section{Differenzen Kodierung}\label{Diff-Testläufe}

Für die Kodierung der Trace Point Differenzen wird zunächst eine zufällig angeordnete DNA-Sequenz und daraus mit der jeweiligen Fehlerrate eine abgewandelte Sequenz berechnet. Dieser Vorgang wiederholt sich mehrfach. Aus einem Sequenzpaar wird dann ein Alignment berechnet, aus dem der CIGAR-String extrahiert wird. Aus diesem werden die Trace Points anhand des $\Delta$-Wertes ausgelesen und die Differenzen der Trace Points bestimmt. Diese werden dann mit den oben beschriebenen Verfahren kodiert und die Anzahl der Bits, die für die jeweilige Kodierung benötigt werden, werden berechnet und deren Verteilung grafisch dargestellt.

\FloatBarrier
\iffalse
Bin/Una: 1.37071633993
Una/Bin: 0.729545545546

Bin/Huf: 1.48491010274
Huf/Bin: 0.673441441441

Huf/Una: 0.923097187768
Una/Huf: 1.08330955099

MAX Bin: 125
MIN Bin: 125
Binary Mean: 125.0

MAX Una: 132
MIN Una: 60
Unary Mean: 91.1931931932

MAX Huf: 126
MIN Huf: 42
Huffman Mean: 84.1801801802
\fi

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/new/tracepoint-1000-5000-d200-015}
	\caption{Häufigkeitsverteilung der Kodierungen der Trace Point Differenzen für \numprint{1000} DNA-Sequenzen mit je \numprint{5000} Basenpaaren, einer Fehlerrate von $15$\% und einem $\Delta$-Wert von $200$.} \label{tracepoint-d200}
\end{figure}

Für die binäre Kodierung der Trace Point Differenzen werden bei einem $\Delta$-Wert von $200$ bei jedem Durchlauf für $24$ Trace Points und den $\Delta$-Wert selbst insgesamt $\lceil \log_225$$\rceil = 125$ Bit benötigt.

Die unäre und Huffman-Kodierungen der Trace Point Differenzen sind Abbildung \ref{tracepoint-d200} dargestellt. Es ist deutlich zu erkennen, dass beide Verteilungen ähnlich verlaufen. Die unäre Kodierung benötigt zwischen $60$ und $132$ Bit und somit $91.19$ Bit im Mittel. Bei der Huffman-Kodierung liegen die Werte zwischen $42$ und $126$ Bit bei einem Mittelwert von $84.18$ Bit. Somit benötigt die Huffman-Kodierung etwa $33$\% weniger Speicher als die binäre Kodierung und etwa $8$\% weniger als die unäre Kodierung.

\iffalse
MAX 50: 130
MIN 50: 45
Mean1: 86.8

MAX 100: 126
MIN 100: 42
Mean2: 80.222

MAX 200: 138
MIN 200: 36
Mean3: 83.376

MAX 500: 90
MIN 500: 25
Mean4: 57.952
\fi

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/new/deltas-1000-5000-015}
	\caption{Häufigkeitsverteilung der Huffman-Kodierungen der Trace Point Differenzen für \numprint{1000} DNA-Sequenzen mit je \numprint{5000} Basenpaaren, einer Fehlerrate von $15$\% und $\Delta$-Werten von $50$, $100$, $200$ und $500$.} \label{deltas}
\end{figure}

Um die Auswirkungen der Wahl des $\Delta$-Parameters messen zu können, wurden, wie oben beschrieben, die Häufigkeitsverteilung der Huffman-Kodierung der Trace Point Differenzen für jeweils \numprint{1000} zufällige Sequenzpaare mit je \numprint{5000} Basenpaaren, einer Fehlerrate von $15$\% und $\Delta$-Werten von $50$, $100$, $200$ und $500$ berechnet. Wie in Abbildung \ref{deltas} zu erkennen ist, liegt die Größe der Kodierung für $\Delta = 50$ zwischen $45$ und $130$ Bit bei einem Mittelwert von $86.8$ Bit. Für $\Delta = 100$ liegen die Werte zwischen $42$ und $126$ Bit und der Mittelwert bei $80.22$ Bit. Weiterhin werden für $\Delta = 200$ Werte zwischen $42$ und $126$ Bit erreicht, bei einem Mittelwert von $84.18$ Bit. Abschließend erreicht die Kodierung für $\Delta = 500$ Werte im Bereich von $25$ und $90$ Bit. Hier liegt der Mittelwert bei $57.95$ Bit.

Somit benötigt die Huffman-Kodierung bei einem groß gewählten $\Delta$ von $500$ etwa ein Drittel weniger Speicher als bei einem klein gewählten $\Delta$-Wert von $50$.

\iffalse
MAX 0.05: 96
MIN 0.05: 24
Mean1: 50.992

MAX 0.15: 128
MIN 0.15: 48
Mean2: 83.032

MAX 0.30: 168
MIN 0.30: 56
Mean3: 114.281

MAX 0.50: 210
MIN 0.50: 90
Mean4: 151.883883884
\fi

\begin{figure}[t]
	\centering
	\includegraphics[width=13cm]{coding/new/errs-1000-5000-d200}
	\caption{Häufigkeitsverteilung der Huffman-Kodierungen der Trace Point Differenzen für \numprint{1000} DNA-Sequenzen mit je \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $100$ und Fehlerraten von $5$\%, $15$\%, $30$\% und $50$\%.} \label{errs-d200}
\end{figure}

Analog zu den verschiedenen $\Delta$-Werten wurde außerdem die Auswirkung der Fehlerrate gemessen. Hierfür wurde die Häufigkeitsverteilung der Huffman-Kodierung für \numprint{1000} Sequenzpaare mit je \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $100$ und Fehlerraten von $5$\%, $15$\%, $30$\% und $50$\% berechnet und in Abbildung \ref{errs-d200} grafisch dargestellt.

Wie in der Abbildung zu erkennen ist, werden für die Huffman-Kodierung mit einer Fehlerrate von $5$\% $24$ bis $96$ Bit benötigt, wobei der Mittelwert bei $50.99$ Bit liegt. Die Kodierung bei einer Fehlerrate von $15$\% benötigt zwischen $48$ und $128$ Bit bei einem Mittelwert von $83.03$ und bei einer Fehlerrate von $30$\% werden $56$ bis $168$ Bit benötigt, wobei der Mittelwert bei $114.28$ Bit liegt. Abschließend werden für eine Kodierung mit einer Fehlerrate von $50$\% zwischen $90$ und $210$ und im Mittel $151.88$ Bit benötigt.

Bei einer geringen Fehlerrate von $5$\% werden somit $66.5$\% weniger Speicher benötigt, als bei einer hohen Fehlerrate von $50$\%.

\section{Entropie der Repräsentationen}

%Cig Entropy Mean: 1755.79258069
%Diff Entropy Mean: 134.698836842
%cig/diff: 13.0349498321
%diff/cig: 0.0767168276731

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{coding/new/entropy-1000-5000-d100}
	\caption{Entropie von \numprint{1000} CIGAR-Strings von DNA-Sequenzen mit je \numprint{5000} Basenpaaren, einem $\Delta$-Wert von $100$ und einer Fehlerrate von $15$\%}
	\label{entropy}
\end{figure}

Die Entropie für die CIGAR-String Repräsentation liegt für die gegebenen Sequenzpaare, wie in Abbildung \ref{entropy} zu erkennen ist, zwischen \numprint{1280} und \numprint{2280} Bit, wobei der Durchschnittswert bei \numprint{1755.79} Bit liegt. Die Werte sind normalverteilt, wobei das Maximum bei $225$ Sequenzpaaren mit etwa \numprint{1800} Bit liegt.

Die Differenzen der Trace Points weisen hingegen eine Entropie im Bereich von $91$ bis $212$ Bit auf, wobei der Durchschnittswert von $134.69$ Bit nur etwa $7.6$\% des Durchschnittwertes der CIGAR-String Repräsentation ausmacht. Das Maximum der Entopie-Werte liegt hier bei etwa bei $220$ Sequenzpaaren mit $130$ Bit.

Zusammenfassend ergibt sich für die Resultate die Tabelle \ref{bits-result}.

\begin{figure}[t]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		&\multicolumn{3}{c|}{CIGAR-String}&\multicolumn{3}{c|}{Trace Point Differenzen ($\Delta = 200$)}\\
		&Min&Max&$\diameter$&Min&Max&$\diameter$\\
		\hline
		Binäre Kodierung&\numprint{4480}&\numprint{9100}&\numprint{6595.50}&125&125&125\\
		\hline
		Unäre Kodierung&\numprint{3500}&\numprint{5100}&\numprint{4290.94}&60&132&90.19\\
		\hline
		Huffman-Kodierung&\numprint{1300}&\numprint{1625}&\numprint{1458.02}&42&126&84.18\\
		\hline
		Entropie&\numprint{1280}&\numprint{2280}&\numprint{1755.79}& 91&212&134.69\\
		\hline
	\end{tabular}
	\caption{Anzahl der Bits für die Kodierungen und Entropie}
	\label{bits-result}
\end{figure}


\chapter{Diskussion}
%TODO hier soll wertend beschrieben werden, was die Resultate bedeuten und wie sich bestimmte Werte erklären lassen
In diesem Kapitel werden die Resultate aus Kapitel \ref{Resultate} interpretiert und die Qualität der Kodierungen in Bezug auf eine speichereffiziente Repräsentation eines Alignments betrachtet.

\section{CIGAR-Kodierung}

Die Kodierungen der CIGAR-Strings, wie sie in Abbildung \ref{cigar-coding} grafisch und in Tabelle \ref{bits-result} numerisch dargestellt sind, zeigen, dass die Huffman-Kodierung mit \numprint{1458.02} Bit im Mittel deutlich weniger Speicher benötigt, als die unäre Kodierung mit \numprint{4290.94} Bit oder die binäre Kodierung mit \numprint{6595.50} Bit.

In CIGAR-Strings von Alignments mit einer geringen Fehlerrate ist die Anzahl der Matches deutlich höher als die der Insertions oder Deletions, was zu großen Quantitäten der 'M'-Operation und kleinen Quantitäten der 'I'- und 'D'-Operationen führt. Insertions und Deletions treffen dazu selten hintereinander auf, was einen Schwerpunkt der Quantität '1' zufolge hat. Für so eine Art der Verteilung ist die binäre Kodierung weniger gut geeignet als die unäre oder Huffman-Kodierung, da sie keine Speicherersparnis aus häufig auftretenden Symbolen ziehen kann, sondern alle Symbole mit der selben Anzahl an Bits kodiert.

Die unäre Kodierung benötigt bei kürzeren Sequenzen, wie bei denen aus Beispiel \ref{Alignment-bsp}, weniger Speicher als die Huffman-Kodierung, da diese für die Dekodierung jedes Mal den 'Header' mitspeichern muss und sich dieser zusätzliche Speicherverbrauch bei kürzeren Sequenzen stärker auswirkt, als bei längeren. In den Resultaten wurden deutlich längere Sequenzen verwendet, weshalb hier die Huffman-Kodierung wie oben beschrieben nur etwa $34$\% des Speicherbedarfs der unären Kodierung benötigt.

Da kürzere Sequenzen hier nur für das Beispiel verwendet wurden und Alignments üblicherweise von längeren Sequenzabschnitten gebildet werden, ist somit die Huffman-Kodierung die speichereffizienteste der drei Verfahren.

\section{Kodierung der Differenzen der Trace Points}

Die Kodierung der Differenzen der Trace Points ist für ein $\Delta = 200$ und eine Fehlerrate von $15$\% in Abbildung \ref{tracepoint-d200} grafisch dargestellt und in der Tabelle \ref{bits-result} numerisch beschrieben. In Abbildung \ref{deltas} sind die Auswirkungen der Wahl des $\Delta$-Parameters dargestellt und in Abbildung \ref{errs-d200} die Auswirkungen der Fehlerrate der Sequenzen.

Für einen $\Delta$-Wert von $200$ benötigt die Huffman-Kodierung im Durchschnitt nur $84.18$ Bit und damit etwa $9.3$\% weniger Speicher, als die unäre Kodierung mit $90.19$ Bit. Die binäre Kodierung liegt mit durchschnittlich $125$ Bit deutlich über dem Bedarf der anderen beiden Kodierungen. Da die einzelnen Abschnitte in der $v$-Sequenz zu $\Delta$ großen Abschnitten der $u$-Sequenz aligniert werden, sind diese üblicherweise auch genauso oder ähnlich groß wie das $\Delta$. Das hat zur Folge, dass die Differenzen der Trace Points in einem ähnlichen Wertebereich liegen und die unäre und Huffman-Kodierung aus dieser Verteilung einen Vorteil ziehen können und daher speichereffizienter kodieren, wobei der Huffman-Algorithmus etwas besser abschneidet als die unäre Kodierung.

Die Wahl des $\Delta$-Wertes kann die Größe der Kodierung deutlich beeinflussen, da dieser Wert die Anzahl der zu speichernden Symbole bestimmt. Bei einem großen $\Delta$ müssen weniger Symbole gespeichert werden und bei einem kleinen $\Delta$ analog mehr. So benötigt die Huffman-Kodierung für ein $\Delta = 500$ folglich nur etwa $66$\% des Speichers als für ein $\Delta = 50$. 

Die Fehlerrate der Sequenzen hat ebenfalls einen großen Einfluss auf die Größe der Kodierung, da für sehr ähnliche Sequenzen mit einer hohen Anzahl an Matches die Trace Points ein Vielfaches von $\Delta$ sind und somit die Differenzen der Trace Points ebenfalls $\Delta$ groß sind und daher deutlich weniger unterschiedliche Symbole kodiert werden müssen. So benötigt die Huffman-Kodierung mit $\Delta = 200$ für eine kleine Fehlerrate von $5$\% im Durchschnitt $50.99$ Bit und damit im Verhältnis zu einer hohen Fehlerrate von $50$\%, welche im Schnitt $151.88$ Bit benötigt, lediglich etwa ein Drittel des Speichers.

\section{Entropie beider Methoden}

Die Entropie der CIGAR-Strings und der Trace Point Differenzen sind in Abbildung \ref{entropy} grafisch dargestellt und in der Tabelle \ref{bits-result} numerisch beschrieben.

Sie gibt den Informationsgehalt einer Sequenz in Relation zu der Verteilung der Symbole an und wird deshalb in Bit pro Symbol berechnet und dann später mit der Anzahl der zu kodierenden Symbole multipliziert. Da ein CIGAR-String alle Edit-Operationen eines Alignments beschreibt und die Trace Point Differenzen lediglich die Abstände von einem zu alignierenden Abschnitt zu dem nächsten beschreiben, müssen in der Regel für CIGAR-Strings mehr Symbole kodiert werden, als für die Trace Point Differenzen. Diese Eigenschaft spiegelt sich auch in der Entropie beider Verfahren wieder. Die CIGAR-Strings weisen eine Entropie von durchschnittlich \numprint{1755,79} Bit auf, was etwa $13$ mal so viel ist wie die Entropie der Trace Point Differenzen, welche bei durchschnittlich $134.69$ Bit liegt.

\chapter{Implementierung}

Die Umsetzung des Trace Point Verfahrens, sowie die Berechnung der verschiedenen Größen der Kodierung ist im Rahmen dieser Arbeit zunächst als Python Implementierung und anschließend als C Implementierung realisiert worden \cite{git}. Der Aufbau als UML-Klassendiagramm ist in Abbildung \ref{UML} zu sehen.

\begin{figure}[h]
\begin{tikzpicture}
\begin{class}[text width=7cm]{Cigar Pattern}{0,-15}
\operation{parse\_cigar()}
\operation{combine(cigar)}
\end{class}

\begin{class}[text width=5.5cm]{Alignment}{5,-5}
\inherit{Cigar Pattern}
\attribute{seq1 : string}
\attribute{seq2 : string}
\attribute{start\_seq1 : int}
\attribute{end\_seq1 : int}
\attribute{start\_seq2 : int}
\attribute{end\_seq2 : int}
\attribute{cigar=\textit{None} : string}
\operation{to\_cigar(seq1, seq2)}
\operation{from\_cigar(seq1, seq2, cigar)}
\operation{show\_aln()}
\end{class}

\begin{class}[text width=5cm]{TracePointAlignment}{-5,-5}
\inherit{Alignment}
\inherit{Cigar Pattern}
\attribute{seq1 : string}
\attribute{seq2 : string}
\attribute{start\_seq1 : int}
\attribute{end\_seq1 : int}
\attribute{start\_seq2 : int}
\attribute{end\_seq2 : int}
\attribute{delta : int}
\operation{encode()}
\operation{decode()}
\operation{store\_tp\_aln()}
\end{class}

\begin{class}[text width=10.5cm]{Main}{0,0}
\inherit{TracePointAlignment}
\inherit{Alignment}
\operation{random\_sequences(amount,length,error\_rate,alphabet)}
\operation{read\_files(seq\_file, aln\_file)}
\end{class}
\end{tikzpicture}
\caption{UML-Diagramm}
\label{UML}
\end{figure}

\section{Funktionalität}

Die entscheidenden Funktionen dieser Implementierung sind die encode()-Funktion, welche aus einem gegebenen CIGAR-String die Trace Points mit Hilfe des $\Delta$-Wertes extrahiert und die decode()-Funktion, welche für gegebene Trace Points und ein $\Delta$ einen CIGAR-String rekonstruiert. Der Pseudocode der encode()-Funktion ist in Algorithmus \ref{encode} und der Pseudocode der decode()-Funktion in Algorithmus \ref{decode} beschrieben. 

Die encode-Funktion extrahiert aus dem gegebenen CIGAR-String die Trace Points, welche dann zusammen mit dem $\Delta$-Wert und den Start- und Endpositionen der Sequenzabschnitte gespeichert werden. Hierbei geht die Information, wie die jeweiligen Intervalle zwischen den Trace Points zu den komplementären Intervallen in der Ursprungssequenz aligniert werden, verloren.
Um bestimmen zu können, wie die einzelnen Abschnitte zueinander aligniert werden, muss in der decode()-Funktion zunächst ein neues Alignment des jeweiligen Intervall-Paares errechnet werden und alle Teilalignments zu einem Gesamtalignment konkateniert werden. Hierbei ist jedoch nicht gewährleistet, dass das neue Alignment dem alten entspricht. Da das neue Alignment aus konkatenierten optimalen Alignments besteht, ist es ebenfalls optimal und hat daher mindestens die gleiche Edit-Distanz wie das alte Alignment.

\begin{algorithm}[t]
	\caption{Berechnung der Trace Points von einem gegebenen CIGAR-String}
	\label{encode}
	\noindent\begin{tabular}{@{}l@{~}l}
		\textbf{Parameter}:
		&$seq1$ und $seq2$ sind die beiden Sequenzen mit den jeweiligen Start- \\
		& und Endpositionen $start\_seq1, end\_seq1$ bzw. $start\_seq2, end\_seq2$. \\
		& Zusätzlich werden der Funktion der $\Delta$-Wert und der CIGAR-String \\
		& übergeben.
	\end{tabular}
	\medskip
	\begin{algorithmic}[1]
		\Function{\textit{encode}}{$seq1, seq2, start\_seq1, end\_seq1, start\_seq2, \Delta, cigar$}
		\State assert($\Size{seq1},\Size{seq2},\Size{cigar}, \Delta > 0$)
		\State assert($start\_seq1, start\_seq2 \geq 0$)
		\State assert($start\_seq1 < end\_seq1$)
		\State \Assign{p}{MAX(1, \Roundup{start\_seq1/\Delta})}
		\State \Assign{\tau}{\Roundup{end\_seq1/\Delta} - \Rounddown{start\_seq2/\Delta}}
		\State \Assign{uTP}{\text{Array for interval termini in the first sequence}}
		\For{\Assign{i}{0} \Upto \(\Size{\tau}\)}
		\State \Assign{uTP[i]}{(p + i) \cdot (\Delta - 1)}
			\EndFor
			\State \Assign{uChars, vChars, count}{0}
			\State \Assign{TP}{\text{Array for Trace Points}}
			\For{\text{each $(cig\_count, cig\_symbol)$ in cigar}}
			\For{\Assign{i}{0} \Upto \(cig\_count\)}
			\If{cig\_symbol = 'I'}
			\State increment $uChars$
			\ElsIf{cig\_symbol = 'D'}
			\State increment $vChars$
			\Else
			\State increment $uChars, vChars$
			\EndIf
			\If{$uChars = uTP[count]$}
			\State $TP$.append($vChars$)
			\EndIf
			\If{$count \neq \Size{uTP} - 1$}
			\State \Return $TP$
			\Else
			\State increment $count$
			\EndIf
			\EndFor
			\EndFor
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}[t]
		\caption{Berechnung eines CIGAR-Strings von einem gegebenen Trace Point Array}
		\label{decode}
		\noindent\begin{tabular}{@{}l@{~}l}
			\textbf{Parameter}:
			&$seq1$ und $seq2$ sind die beiden Sequenzen. \\
			& Zusätzlich werden der Funktion der $\Delta$-Wert und das Trace Point Array \\
			& übergeben.
		\end{tabular}
		\medskip
		\begin{algorithmic}[1]
			\Function{\textit{decode}}{$seq1, seq2, \Delta, TP$}
			\State assert($\Size{seq1}, \Size{seq2}, \Delta, \Size{TP} > 0$)
			\State \Assign{cig}{\text{empty String}}
			\For{\Assign{i}{0} \Upto \(\Size{TP}\)}
			\If{i = 0}
			\State $cig$.append$(\textbf{cigar}(seq1[0...\Delta], seq2[0...TP[i] + 1]))$
			\ElsIf{i = \Size{TP} - 1}
			\State $cig$.append$(\textbf{cigar}(seq1[i \cdot \Delta...\Size{seq1}], seq2[TP[i - 1] + 1...\Size{seq2}]))$
			\Else
			\State $cig$.append$(\textbf{cigar}(seq1[i \cdot \Delta...(i + 1) \cdot \Delta],seq2[TP[i - 1] + 1]...TP[i] + 1))$
			\EndIf
			\EndFor
			\State \Assign{cig}{\textbf{combine}(cig)}
			\State \Return cig
			\EndFunction\\
			
			\Function{\textit{combine}}{$cigar$}
			\State \Assign{cig}{\text{empty String}}
			\State \Assign{tmp}{0}
			\For{\text{each $cig\_count, cig\_symbol$ in cigar}}
			\State \Assign{tmp}{tmp + previous\_cig\_count}
			\If{cig\_symbol = previous\_cig\_symbol}
			\If{\text{not last element in cigar}}
			\State \Assign{tmp}{0}
			\EndIf
			\EndIf
			\If{\text{last element is in cigar}}
			\State $cig$.append$(tmp + cig\_count, cig\_symbol)$
			\EndIf
			\EndFor
			\State \Return cig
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
\chapter{Fazit}

Das Verfahren der Trace Point Differenzen stellt im Vergleich zu der üblichen Repräsentation von Alignments als CIGAR-String eine deutlich speichereffizientere Methode dar. Insbesondere durch eine Huffman-Kodierung der Differenzwerte kann bei den in dieser Arbeit errechneten Größen eine Speicherersparnis von etwa $94$\% gegenüber den CIGAR-Strings erzielt werden. Hierbei spielt jedoch der vorher definierte positive Parameter $\Delta$ eine entscheidende Rolle.

Umso größer $\Delta$ gewählt ist, umso weniger Trace Points werden gespeichert und umso länger dauert die Berechnung, um die Teil-Alignments zu rekonstruieren. Bei einem kleinen $\Delta$ werden analog mehr Trace Points gespeichert, aber die Rekonstruktionszeit der Teil-Alignments ist geringer.

Mithilfe von $\Delta$ lässt sich somit ein Trade-Off zwischen dem Speicherplatzverbrauch und dem Zeitbedarf für die Rekonstruktion der Teil-Alignments einstellen.